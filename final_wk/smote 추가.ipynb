{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114891af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score \n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9cecb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_df2.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d231150",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2cff4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ELMO2</th>\n",
       "      <th>CREB3L1</th>\n",
       "      <th>RPS11</th>\n",
       "      <th>PNMA1</th>\n",
       "      <th>MMP2</th>\n",
       "      <th>C10orf90</th>\n",
       "      <th>ZHX3</th>\n",
       "      <th>ERCC5</th>\n",
       "      <th>GPR98</th>\n",
       "      <th>RXFP3</th>\n",
       "      <th>...</th>\n",
       "      <th>SLC2A11</th>\n",
       "      <th>GRIP2</th>\n",
       "      <th>GPLD1</th>\n",
       "      <th>RAB8A</th>\n",
       "      <th>RXFP2</th>\n",
       "      <th>PIK3IP1</th>\n",
       "      <th>SLC39A6</th>\n",
       "      <th>SNRPD2</th>\n",
       "      <th>AQP7</th>\n",
       "      <th>CTSC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.886827</td>\n",
       "      <td>0.349044</td>\n",
       "      <td>0.159261</td>\n",
       "      <td>-1.586876</td>\n",
       "      <td>-0.783517</td>\n",
       "      <td>-0.651792</td>\n",
       "      <td>-0.192552</td>\n",
       "      <td>-0.688943</td>\n",
       "      <td>1.790315</td>\n",
       "      <td>0.606942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618291</td>\n",
       "      <td>-0.244858</td>\n",
       "      <td>0.087421</td>\n",
       "      <td>-0.441970</td>\n",
       "      <td>0.805609</td>\n",
       "      <td>0.084007</td>\n",
       "      <td>-0.853409</td>\n",
       "      <td>-0.767943</td>\n",
       "      <td>-0.097567</td>\n",
       "      <td>0.208945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.076357</td>\n",
       "      <td>0.902533</td>\n",
       "      <td>0.026440</td>\n",
       "      <td>1.624105</td>\n",
       "      <td>1.396133</td>\n",
       "      <td>0.195322</td>\n",
       "      <td>0.394281</td>\n",
       "      <td>0.733565</td>\n",
       "      <td>1.460883</td>\n",
       "      <td>-0.288978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083736</td>\n",
       "      <td>-0.957388</td>\n",
       "      <td>0.095699</td>\n",
       "      <td>0.972672</td>\n",
       "      <td>0.691112</td>\n",
       "      <td>1.004964</td>\n",
       "      <td>-0.178898</td>\n",
       "      <td>-0.945141</td>\n",
       "      <td>0.843130</td>\n",
       "      <td>-1.062326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.160544</td>\n",
       "      <td>0.875732</td>\n",
       "      <td>4.027129</td>\n",
       "      <td>0.072768</td>\n",
       "      <td>0.488563</td>\n",
       "      <td>-0.707819</td>\n",
       "      <td>-1.258655</td>\n",
       "      <td>2.353938</td>\n",
       "      <td>1.514641</td>\n",
       "      <td>-0.194159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561794</td>\n",
       "      <td>-0.680456</td>\n",
       "      <td>-0.348212</td>\n",
       "      <td>0.766775</td>\n",
       "      <td>-0.167253</td>\n",
       "      <td>0.878351</td>\n",
       "      <td>1.027238</td>\n",
       "      <td>-0.487267</td>\n",
       "      <td>0.630930</td>\n",
       "      <td>-0.273803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.093755</td>\n",
       "      <td>0.023215</td>\n",
       "      <td>-1.310286</td>\n",
       "      <td>0.819120</td>\n",
       "      <td>-0.815949</td>\n",
       "      <td>-0.407544</td>\n",
       "      <td>0.793497</td>\n",
       "      <td>-0.158602</td>\n",
       "      <td>-0.161729</td>\n",
       "      <td>1.060372</td>\n",
       "      <td>...</td>\n",
       "      <td>2.103530</td>\n",
       "      <td>-1.246807</td>\n",
       "      <td>-1.676863</td>\n",
       "      <td>0.213831</td>\n",
       "      <td>-1.585708</td>\n",
       "      <td>0.933448</td>\n",
       "      <td>0.740015</td>\n",
       "      <td>-1.050423</td>\n",
       "      <td>-0.987469</td>\n",
       "      <td>-0.644158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.249586</td>\n",
       "      <td>-0.633865</td>\n",
       "      <td>-0.325074</td>\n",
       "      <td>0.155425</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>-0.462644</td>\n",
       "      <td>-0.576603</td>\n",
       "      <td>-1.569976</td>\n",
       "      <td>-1.943742</td>\n",
       "      <td>0.022223</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.478282</td>\n",
       "      <td>0.569776</td>\n",
       "      <td>-0.794047</td>\n",
       "      <td>-0.079013</td>\n",
       "      <td>0.559841</td>\n",
       "      <td>-0.793164</td>\n",
       "      <td>-1.567624</td>\n",
       "      <td>0.733505</td>\n",
       "      <td>-0.957059</td>\n",
       "      <td>0.428773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17814 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ELMO2   CREB3L1     RPS11     PNMA1      MMP2  C10orf90      ZHX3  \\\n",
       "0  0.886827  0.349044  0.159261 -1.586876 -0.783517 -0.651792 -0.192552   \n",
       "1 -0.076357  0.902533  0.026440  1.624105  1.396133  0.195322  0.394281   \n",
       "2  1.160544  0.875732  4.027129  0.072768  0.488563 -0.707819 -1.258655   \n",
       "3 -0.093755  0.023215 -1.310286  0.819120 -0.815949 -0.407544  0.793497   \n",
       "4 -0.249586 -0.633865 -0.325074  0.155425  0.019339 -0.462644 -0.576603   \n",
       "\n",
       "      ERCC5     GPR98     RXFP3  ...   SLC2A11     GRIP2     GPLD1     RAB8A  \\\n",
       "0 -0.688943  1.790315  0.606942  ...  0.618291 -0.244858  0.087421 -0.441970   \n",
       "1  0.733565  1.460883 -0.288978  ...  0.083736 -0.957388  0.095699  0.972672   \n",
       "2  2.353938  1.514641 -0.194159  ...  0.561794 -0.680456 -0.348212  0.766775   \n",
       "3 -0.158602 -0.161729  1.060372  ...  2.103530 -1.246807 -1.676863  0.213831   \n",
       "4 -1.569976 -1.943742  0.022223  ... -1.478282  0.569776 -0.794047 -0.079013   \n",
       "\n",
       "      RXFP2   PIK3IP1   SLC39A6    SNRPD2      AQP7      CTSC  \n",
       "0  0.805609  0.084007 -0.853409 -0.767943 -0.097567  0.208945  \n",
       "1  0.691112  1.004964 -0.178898 -0.945141  0.843130 -1.062326  \n",
       "2 -0.167253  0.878351  1.027238 -0.487267  0.630930 -0.273803  \n",
       "3 -1.585708  0.933448  0.740015 -1.050423 -0.987469 -0.644158  \n",
       "4  0.559841 -0.793164 -1.567624  0.733505 -0.957059  0.428773  \n",
       "\n",
       "[5 rows x 17814 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_df = StandardScaler().fit_transform(X)\n",
    "std_df = pd.DataFrame(std_df, index=X.index, columns=X.columns)\n",
    "df2 = std_df\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9b464aa0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 학습용 피처/레이블 데이터 세트 :  (590, 17814) (590,)\n",
      "SMOTE 적용 후 학습용 피처/레이블 데이터 세트 : (1058, 17814) (1058,)\n",
      "SMOTE 적용 후 값의 분포 :\n",
      " 1    529\n",
      "0    529\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "smote = SMOTE(random_state=42)\n",
    "X_train_over, y_train_over = smote.fit_resample(X, y)\n",
    "print(\"SMOTE 적용 전 학습용 피처/레이블 데이터 세트 : \", X.shape, y.shape)\n",
    "print('SMOTE 적용 후 학습용 피처/레이블 데이터 세트 :', X_train_over.shape, y_train_over.shape)\n",
    "print('SMOTE 적용 후 값의 분포 :\\n',pd.Series(y_train_over).value_counts() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2e9db68b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SMOTE 적용 전 값의 분포 :\n",
      " 1    529\n",
      "0     61\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print('SMOTE 적용 전 값의 분포 :\\n',pd.Series(y).value_counts() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e177437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=516)\n",
    "pca_array = pca.fit_transform(X_train_over)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fdcb3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train_over)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "# 주성분의 개수를 지정하지 않고 찾아줌\n",
    "# 분산의 비율을 누적해서 더한 값이 95% 이상인 주성분의 개수\n",
    "# 즉, 분산의 95%이상 유지\n",
    "d = np.argmax(cumsum >= 0.99) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df171715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b5d9475f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1058, 516)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec=PCA(0.99)\n",
    "x2=dec.fit_transform(X_train_over)\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "952fc1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x, x_test, y, y_test=train_test_split(pca_array,y_train_over,test_size= 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "232e75ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimators_repeater(estimators=[RandomForestClassifier(),AdaBoostClassifier(),SVC()],tr_slicer=(None,None),tst_slicer=(None,None),loops=300,scorer=accuracy_score,x=x,y=y):\n",
    "    training_score={}\n",
    "    testing_score={}\n",
    "    timing={}\n",
    "    for cl in estimators:\n",
    "        cl_name=cl.__class__.__name__\n",
    "        training_score[cl_name]=[]\n",
    "        testing_score[cl_name]=[]\n",
    "        timing[cl_name]=[]\n",
    "    for i in range(loops):\n",
    "        k1=time()\n",
    "        x_train, x_test, y_train, y_test=train_test_split(x,y,random_state=i)\n",
    "        for cl in estimators:\n",
    "            a=time()\n",
    "            cl_name=cl.__class__.__name__\n",
    "            clean_cl=clone(cl)\n",
    "            clean_cl.fit(x_train[tr_slicer[0]:tr_slicer[1]],y_train[tr_slicer[0]:tr_slicer[1]])\n",
    "            training_score[cl_name].append(scorer(y_train[tr_slicer[0]:tr_slicer[1]],clean_cl.predict(x_train[tr_slicer[0]:tr_slicer[1]])))\n",
    "            testing_score[cl_name].append(scorer(y_test[tst_slicer[0]:tst_slicer[1]],clean_cl.predict(x_test[tst_slicer[0]:tst_slicer[1]])))\n",
    "            b=time()                                \n",
    "            timing[cl_name].append(b-a)\n",
    "        k2=time()\n",
    "        print(f'number {i} out of {loops} took {k2-k1} seconds')\n",
    "    global training_score_df\n",
    "    training_score_df=pd.DataFrame(training_score)\n",
    "    global testing_score_df\n",
    "    testing_score_df=pd.DataFrame(testing_score)\n",
    "    global timing_df\n",
    "    timing_df=pd.DataFrame(timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "80c99c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 0 out of 300 took 2.4903407096862793 seconds\n",
      "number 1 out of 300 took 2.4314992427825928 seconds\n",
      "number 2 out of 300 took 2.4783735275268555 seconds\n",
      "number 3 out of 300 took 2.453441619873047 seconds\n",
      "number 4 out of 300 took 2.4644103050231934 seconds\n",
      "number 5 out of 300 took 2.6628806591033936 seconds\n",
      "number 6 out of 300 took 2.5212595462799072 seconds\n",
      "number 7 out of 300 took 2.627974271774292 seconds\n",
      "number 8 out of 300 took 2.454437732696533 seconds\n",
      "number 9 out of 300 took 2.476379632949829 seconds\n",
      "number 10 out of 300 took 2.57910418510437 seconds\n",
      "number 11 out of 300 took 2.509291410446167 seconds\n",
      "number 12 out of 300 took 2.4195311069488525 seconds\n",
      "number 13 out of 300 took 2.502310276031494 seconds\n",
      "number 14 out of 300 took 2.594064950942993 seconds\n",
      "number 15 out of 300 took 2.5013134479522705 seconds\n",
      "number 16 out of 300 took 2.5132806301116943 seconds\n",
      "number 17 out of 300 took 2.701777935028076 seconds\n",
      "number 18 out of 300 took 2.625978469848633 seconds\n",
      "number 19 out of 300 took 2.4624171257019043 seconds\n",
      "number 20 out of 300 took 2.369663953781128 seconds\n",
      "number 21 out of 300 took 2.404571056365967 seconds\n",
      "number 22 out of 300 took 2.3886139392852783 seconds\n",
      "number 23 out of 300 took 2.4005820751190186 seconds\n",
      "number 24 out of 300 took 2.3935985565185547 seconds\n",
      "number 25 out of 300 took 2.3955960273742676 seconds\n",
      "number 26 out of 300 took 2.4225220680236816 seconds\n",
      "number 27 out of 300 took 2.394598960876465 seconds\n",
      "number 28 out of 300 took 2.403573989868164 seconds\n",
      "number 29 out of 300 took 2.384624481201172 seconds\n",
      "number 30 out of 300 took 2.4045705795288086 seconds\n",
      "number 31 out of 300 took 2.4065663814544678 seconds\n",
      "number 32 out of 300 took 2.385622024536133 seconds\n",
      "number 33 out of 300 took 2.383626937866211 seconds\n",
      "number 34 out of 300 took 2.401580333709717 seconds\n",
      "number 35 out of 300 took 2.4025766849517822 seconds\n",
      "number 36 out of 300 took 2.406564950942993 seconds\n",
      "number 37 out of 300 took 2.4025774002075195 seconds\n",
      "number 38 out of 300 took 2.3975892066955566 seconds\n",
      "number 39 out of 300 took 2.4015796184539795 seconds\n",
      "number 40 out of 300 took 2.4065656661987305 seconds\n",
      "number 41 out of 300 took 2.383626699447632 seconds\n",
      "number 42 out of 300 took 2.3955957889556885 seconds\n",
      "number 43 out of 300 took 2.3936009407043457 seconds\n",
      "number 44 out of 300 took 2.402575969696045 seconds\n",
      "number 45 out of 300 took 2.395595073699951 seconds\n",
      "number 46 out of 300 took 2.397590160369873 seconds\n",
      "number 47 out of 300 took 2.398587465286255 seconds\n",
      "number 48 out of 300 took 2.403573513031006 seconds\n",
      "number 49 out of 300 took 2.3965933322906494 seconds\n",
      "number 50 out of 300 took 2.4095585346221924 seconds\n",
      "number 51 out of 300 took 2.3866186141967773 seconds\n",
      "number 52 out of 300 took 2.4145448207855225 seconds\n",
      "number 53 out of 300 took 2.3975906372070312 seconds\n",
      "number 54 out of 300 took 2.498321056365967 seconds\n",
      "number 55 out of 300 took 2.556166172027588 seconds\n",
      "number 56 out of 300 took 2.4464592933654785 seconds\n",
      "number 57 out of 300 took 2.4664065837860107 seconds\n",
      "number 58 out of 300 took 2.438481092453003 seconds\n",
      "number 59 out of 300 took 2.4634132385253906 seconds\n",
      "number 60 out of 300 took 2.429504632949829 seconds\n",
      "number 61 out of 300 took 2.445462226867676 seconds\n",
      "number 62 out of 300 took 2.388613224029541 seconds\n",
      "number 63 out of 300 took 2.4075632095336914 seconds\n",
      "number 64 out of 300 took 2.3965914249420166 seconds\n",
      "number 65 out of 300 took 2.4035751819610596 seconds\n",
      "number 66 out of 300 took 2.4135468006134033 seconds\n",
      "number 67 out of 300 took 2.3975889682769775 seconds\n",
      "number 68 out of 300 took 2.4334943294525146 seconds\n",
      "number 69 out of 300 took 2.422523021697998 seconds\n",
      "number 70 out of 300 took 2.384625196456909 seconds\n",
      "number 71 out of 300 took 2.4085617065429688 seconds\n",
      "number 72 out of 300 took 2.4015796184539795 seconds\n",
      "number 73 out of 300 took 2.392603874206543 seconds\n",
      "number 74 out of 300 took 2.417536973953247 seconds\n",
      "number 75 out of 300 took 2.4125494956970215 seconds\n",
      "number 76 out of 300 took 2.427509307861328 seconds\n",
      "number 77 out of 300 took 2.4035749435424805 seconds\n",
      "number 78 out of 300 took 2.389611005783081 seconds\n",
      "number 79 out of 300 took 2.4075629711151123 seconds\n",
      "number 80 out of 300 took 2.3965933322906494 seconds\n",
      "number 81 out of 300 took 2.4035732746124268 seconds\n",
      "number 82 out of 300 took 2.392604351043701 seconds\n",
      "number 83 out of 300 took 2.4434666633605957 seconds\n",
      "number 84 out of 300 took 2.42451810836792 seconds\n",
      "number 85 out of 300 took 2.38362717628479 seconds\n",
      "number 86 out of 300 took 2.3945980072021484 seconds\n",
      "number 87 out of 300 took 2.4035730361938477 seconds\n",
      "number 88 out of 300 took 2.4085617065429688 seconds\n",
      "number 89 out of 300 took 2.412550449371338 seconds\n",
      "number 90 out of 300 took 2.38761568069458 seconds\n",
      "number 91 out of 300 took 2.3955957889556885 seconds\n",
      "number 92 out of 300 took 2.4085605144500732 seconds\n",
      "number 93 out of 300 took 2.3985865116119385 seconds\n",
      "number 94 out of 300 took 2.4045708179473877 seconds\n",
      "number 95 out of 300 took 2.396592617034912 seconds\n",
      "number 96 out of 300 took 2.4235212802886963 seconds\n",
      "number 97 out of 300 took 2.407564401626587 seconds\n",
      "number 98 out of 300 took 2.38362717628479 seconds\n",
      "number 99 out of 300 took 2.3806345462799072 seconds\n",
      "number 100 out of 300 took 2.3936004638671875 seconds\n",
      "number 101 out of 300 took 2.3945977687835693 seconds\n",
      "number 102 out of 300 took 2.3906095027923584 seconds\n",
      "number 103 out of 300 took 2.4085607528686523 seconds\n",
      "number 104 out of 300 took 2.404571533203125 seconds\n",
      "number 105 out of 300 took 2.4055683612823486 seconds\n",
      "number 106 out of 300 took 2.4275107383728027 seconds\n",
      "number 107 out of 300 took 2.409557342529297 seconds\n",
      "number 108 out of 300 took 2.4005823135375977 seconds\n",
      "number 109 out of 300 took 2.414544105529785 seconds\n",
      "number 110 out of 300 took 2.3965933322906494 seconds\n",
      "number 111 out of 300 took 2.4045708179473877 seconds\n",
      "number 112 out of 300 took 2.398587226867676 seconds\n",
      "number 113 out of 300 took 2.4075636863708496 seconds\n",
      "number 114 out of 300 took 2.370661973953247 seconds\n",
      "number 115 out of 300 took 2.404571533203125 seconds\n",
      "number 116 out of 300 took 2.3916056156158447 seconds\n",
      "number 117 out of 300 took 2.4055700302124023 seconds\n",
      "number 118 out of 300 took 2.4055683612823486 seconds\n",
      "number 119 out of 300 took 2.4095587730407715 seconds\n",
      "number 120 out of 300 took 2.395595073699951 seconds\n",
      "number 121 out of 300 took 2.393601179122925 seconds\n",
      "number 122 out of 300 took 2.399585008621216 seconds\n",
      "number 123 out of 300 took 2.404571056365967 seconds\n",
      "number 124 out of 300 took 2.4474568367004395 seconds\n",
      "number 125 out of 300 took 2.458428144454956 seconds\n",
      "number 126 out of 300 took 2.421525001525879 seconds\n",
      "number 127 out of 300 took 2.416539430618286 seconds\n",
      "number 128 out of 300 took 2.3886139392852783 seconds\n",
      "number 129 out of 300 took 2.390608549118042 seconds\n",
      "number 130 out of 300 took 2.4215264320373535 seconds\n",
      "number 131 out of 300 took 2.371659755706787 seconds\n",
      "number 132 out of 300 took 2.410555362701416 seconds\n",
      "number 133 out of 300 took 2.3876161575317383 seconds\n",
      "number 134 out of 300 took 2.3836276531219482 seconds\n",
      "number 135 out of 300 took 2.4135472774505615 seconds\n",
      "number 136 out of 300 took 2.396592617034912 seconds\n",
      "number 137 out of 300 took 2.4135470390319824 seconds\n",
      "number 138 out of 300 took 2.396592617034912 seconds\n",
      "number 139 out of 300 took 2.3945977687835693 seconds\n",
      "number 140 out of 300 took 2.399585247039795 seconds\n",
      "number 141 out of 300 took 2.3955955505371094 seconds\n",
      "number 142 out of 300 took 2.4454615116119385 seconds\n",
      "number 143 out of 300 took 2.4295053482055664 seconds\n",
      "number 144 out of 300 took 2.4384801387786865 seconds\n",
      "number 145 out of 300 took 2.401580333709717 seconds\n",
      "number 146 out of 300 took 2.3876166343688965 seconds\n",
      "number 147 out of 300 took 2.4095587730407715 seconds\n",
      "number 148 out of 300 took 2.373654365539551 seconds\n",
      "number 149 out of 300 took 2.400580644607544 seconds\n",
      "number 150 out of 300 took 2.407564401626587 seconds\n",
      "number 151 out of 300 took 2.3985869884490967 seconds\n",
      "number 152 out of 300 took 2.4115538597106934 seconds\n",
      "number 153 out of 300 took 2.426513433456421 seconds\n",
      "number 154 out of 300 took 2.425515651702881 seconds\n",
      "number 155 out of 300 took 2.4185333251953125 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 156 out of 300 took 2.3995845317840576 seconds\n",
      "number 157 out of 300 took 2.4015793800354004 seconds\n",
      "number 158 out of 300 took 2.383626937866211 seconds\n",
      "number 159 out of 300 took 2.3955960273742676 seconds\n",
      "number 160 out of 300 took 2.3826303482055664 seconds\n",
      "number 161 out of 300 took 2.4205286502838135 seconds\n",
      "number 162 out of 300 took 2.38262939453125 seconds\n",
      "number 163 out of 300 took 2.3995847702026367 seconds\n",
      "number 164 out of 300 took 2.416539192199707 seconds\n",
      "number 165 out of 300 took 2.4025776386260986 seconds\n",
      "number 166 out of 300 took 2.445462703704834 seconds\n",
      "number 167 out of 300 took 2.4813649654388428 seconds\n",
      "number 168 out of 300 took 2.4125494956970215 seconds\n",
      "number 169 out of 300 took 2.397590160369873 seconds\n",
      "number 170 out of 300 took 2.384625196456909 seconds\n",
      "number 171 out of 300 took 2.4005825519561768 seconds\n",
      "number 172 out of 300 took 2.3926031589508057 seconds\n",
      "number 173 out of 300 took 2.400583028793335 seconds\n",
      "number 174 out of 300 took 2.42850661277771 seconds\n",
      "number 175 out of 300 took 2.3806354999542236 seconds\n",
      "number 176 out of 300 took 2.401578187942505 seconds\n",
      "number 177 out of 300 took 2.4225239753723145 seconds\n",
      "number 178 out of 300 took 2.4205288887023926 seconds\n",
      "number 179 out of 300 took 2.4135468006134033 seconds\n",
      "number 180 out of 300 took 2.3965933322906494 seconds\n",
      "number 181 out of 300 took 2.403573989868164 seconds\n",
      "number 182 out of 300 took 2.392603635787964 seconds\n",
      "number 183 out of 300 took 2.4115519523620605 seconds\n",
      "number 184 out of 300 took 2.372657537460327 seconds\n",
      "number 185 out of 300 took 2.427509307861328 seconds\n",
      "number 186 out of 300 took 2.3926031589508057 seconds\n",
      "number 187 out of 300 took 2.4015800952911377 seconds\n",
      "number 188 out of 300 took 2.410555601119995 seconds\n",
      "number 189 out of 300 took 2.3866190910339355 seconds\n",
      "number 190 out of 300 took 2.4045705795288086 seconds\n",
      "number 191 out of 300 took 2.3896117210388184 seconds\n",
      "number 192 out of 300 took 2.4025776386260986 seconds\n",
      "number 193 out of 300 took 2.4045701026916504 seconds\n",
      "number 194 out of 300 took 2.3975906372070312 seconds\n",
      "number 195 out of 300 took 2.4105544090270996 seconds\n",
      "number 196 out of 300 took 2.3965933322906494 seconds\n",
      "number 197 out of 300 took 2.4065659046173096 seconds\n",
      "number 198 out of 300 took 2.396592378616333 seconds\n",
      "number 199 out of 300 took 2.3856217861175537 seconds\n",
      "number 200 out of 300 took 2.399585247039795 seconds\n",
      "number 201 out of 300 took 2.3916053771972656 seconds\n",
      "number 202 out of 300 took 2.3806352615356445 seconds\n",
      "number 203 out of 300 took 2.4105560779571533 seconds\n",
      "number 204 out of 300 took 2.3995845317840576 seconds\n",
      "number 205 out of 300 took 2.401578903198242 seconds\n",
      "number 206 out of 300 took 2.3826308250427246 seconds\n",
      "number 207 out of 300 took 2.3975908756256104 seconds\n",
      "number 208 out of 300 took 2.3985867500305176 seconds\n",
      "number 209 out of 300 took 2.3816328048706055 seconds\n",
      "number 210 out of 300 took 2.409558057785034 seconds\n",
      "number 211 out of 300 took 2.369663953781128 seconds\n",
      "number 212 out of 300 took 2.399585723876953 seconds\n",
      "number 213 out of 300 took 2.38362717628479 seconds\n",
      "number 214 out of 300 took 2.3985865116119385 seconds\n",
      "number 215 out of 300 took 2.4245188236236572 seconds\n",
      "number 216 out of 300 took 2.381632089614868 seconds\n",
      "number 217 out of 300 took 2.424517869949341 seconds\n",
      "number 218 out of 300 took 2.4165401458740234 seconds\n",
      "number 219 out of 300 took 2.3866190910339355 seconds\n",
      "number 220 out of 300 took 2.4185338020324707 seconds\n",
      "number 221 out of 300 took 2.4055683612823486 seconds\n",
      "number 222 out of 300 took 2.4065663814544678 seconds\n",
      "number 223 out of 300 took 2.4015793800354004 seconds\n",
      "number 224 out of 300 took 2.4145445823669434 seconds\n",
      "number 225 out of 300 took 2.377643346786499 seconds\n",
      "number 226 out of 300 took 2.4235215187072754 seconds\n",
      "number 227 out of 300 took 2.412550210952759 seconds\n",
      "number 228 out of 300 took 2.4185338020324707 seconds\n",
      "number 229 out of 300 took 2.395595073699951 seconds\n",
      "number 230 out of 300 took 2.4305012226104736 seconds\n",
      "number 231 out of 300 took 2.3906090259552 seconds\n",
      "number 232 out of 300 took 2.3945975303649902 seconds\n",
      "number 233 out of 300 took 2.4095587730407715 seconds\n",
      "number 234 out of 300 took 2.3995845317840576 seconds\n",
      "number 235 out of 300 took 2.411552906036377 seconds\n",
      "number 236 out of 300 took 2.3796377182006836 seconds\n",
      "number 237 out of 300 took 2.412550926208496 seconds\n",
      "number 238 out of 300 took 2.3806354999542236 seconds\n",
      "number 239 out of 300 took 2.421525478363037 seconds\n",
      "number 240 out of 300 took 2.3816330432891846 seconds\n",
      "number 241 out of 300 took 2.3906090259552 seconds\n",
      "number 242 out of 300 took 2.415541648864746 seconds\n",
      "number 243 out of 300 took 2.4075636863708496 seconds\n",
      "number 244 out of 300 took 2.4005825519561768 seconds\n",
      "number 245 out of 300 took 2.3776426315307617 seconds\n",
      "number 246 out of 300 took 2.4165403842926025 seconds\n",
      "number 247 out of 300 took 2.4035732746124268 seconds\n",
      "number 248 out of 300 took 2.406566619873047 seconds\n",
      "number 249 out of 300 took 2.4075632095336914 seconds\n",
      "number 250 out of 300 took 2.411552667617798 seconds\n",
      "number 251 out of 300 took 2.390608549118042 seconds\n",
      "number 252 out of 300 took 2.3906078338623047 seconds\n",
      "number 253 out of 300 took 2.4145448207855225 seconds\n",
      "number 254 out of 300 took 2.397590398788452 seconds\n",
      "number 255 out of 300 took 2.399585008621216 seconds\n",
      "number 256 out of 300 took 2.3995838165283203 seconds\n",
      "number 257 out of 300 took 2.390608549118042 seconds\n",
      "number 258 out of 300 took 2.4155421257019043 seconds\n",
      "number 259 out of 300 took 2.404572010040283 seconds\n",
      "number 260 out of 300 took 2.4055681228637695 seconds\n",
      "number 261 out of 300 took 2.428507089614868 seconds\n",
      "number 262 out of 300 took 2.3766465187072754 seconds\n",
      "number 263 out of 300 took 2.4005818367004395 seconds\n",
      "number 264 out of 300 took 2.3975906372070312 seconds\n",
      "number 265 out of 300 took 2.395594835281372 seconds\n",
      "number 266 out of 300 took 2.3686676025390625 seconds\n",
      "number 267 out of 300 took 2.4095582962036133 seconds\n",
      "number 268 out of 300 took 2.4185330867767334 seconds\n",
      "number 269 out of 300 took 2.38961124420166 seconds\n",
      "number 270 out of 300 took 2.3816325664520264 seconds\n",
      "number 271 out of 300 took 2.4055685997009277 seconds\n",
      "number 272 out of 300 took 2.4125499725341797 seconds\n",
      "number 273 out of 300 took 2.417536497116089 seconds\n",
      "number 274 out of 300 took 2.412550687789917 seconds\n",
      "number 275 out of 300 took 2.3955960273742676 seconds\n",
      "number 276 out of 300 took 2.404572010040283 seconds\n",
      "number 277 out of 300 took 2.393599271774292 seconds\n",
      "number 278 out of 300 took 2.3985884189605713 seconds\n",
      "number 279 out of 300 took 2.4005818367004395 seconds\n",
      "number 280 out of 300 took 2.409558057785034 seconds\n",
      "number 281 out of 300 took 2.3945980072021484 seconds\n",
      "number 282 out of 300 took 2.404571294784546 seconds\n",
      "number 283 out of 300 took 2.411552906036377 seconds\n",
      "number 284 out of 300 took 2.384624481201172 seconds\n",
      "number 285 out of 300 took 2.403574228286743 seconds\n",
      "number 286 out of 300 took 2.3886144161224365 seconds\n",
      "number 287 out of 300 took 2.411552667617798 seconds\n",
      "number 288 out of 300 took 2.3726561069488525 seconds\n",
      "number 289 out of 300 took 2.393601894378662 seconds\n",
      "number 290 out of 300 took 2.390608072280884 seconds\n",
      "number 291 out of 300 took 2.4544379711151123 seconds\n",
      "number 292 out of 300 took 2.4823639392852783 seconds\n",
      "number 293 out of 300 took 2.3936004638671875 seconds\n",
      "number 294 out of 300 took 2.3936007022857666 seconds\n",
      "number 295 out of 300 took 2.3965935707092285 seconds\n",
      "number 296 out of 300 took 2.394597291946411 seconds\n",
      "number 297 out of 300 took 2.424517869949341 seconds\n",
      "number 298 out of 300 took 2.3965933322906494 seconds\n",
      "number 299 out of 300 took 2.4324965476989746 seconds\n"
     ]
    }
   ],
   "source": [
    "estimators_repeater(estimators=[RandomForestClassifier(),AdaBoostClassifier(),SVC(),LogisticRegression()],x=x,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31f3310e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LogisticRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.999022</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000767</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998423</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998423</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.998423</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RandomForestClassifier  AdaBoostClassifier         SVC  \\\n",
       "count                   300.0               300.0  300.000000   \n",
       "mean                      1.0                 1.0    0.999022   \n",
       "std                       0.0                 0.0    0.000767   \n",
       "min                       1.0                 1.0    0.998423   \n",
       "25%                       1.0                 1.0    0.998423   \n",
       "50%                       1.0                 1.0    0.998423   \n",
       "75%                       1.0                 1.0    1.000000   \n",
       "max                       1.0                 1.0    1.000000   \n",
       "\n",
       "       LogisticRegression  \n",
       "count               300.0  \n",
       "mean                  1.0  \n",
       "std                   0.0  \n",
       "min                   1.0  \n",
       "25%                   1.0  \n",
       "50%                   1.0  \n",
       "75%                   1.0  \n",
       "max                   1.0  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_score_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "16b3db99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LogisticRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.992233</td>\n",
       "      <td>0.996509</td>\n",
       "      <td>0.997720</td>\n",
       "      <td>0.998113</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.006893</td>\n",
       "      <td>0.004117</td>\n",
       "      <td>0.002740</td>\n",
       "      <td>0.002700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.962264</td>\n",
       "      <td>0.981132</td>\n",
       "      <td>0.990566</td>\n",
       "      <td>0.990566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.990566</td>\n",
       "      <td>0.995283</td>\n",
       "      <td>0.995283</td>\n",
       "      <td>0.995283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.995283</td>\n",
       "      <td>0.995283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.995283</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RandomForestClassifier  AdaBoostClassifier         SVC  \\\n",
       "count              300.000000          300.000000  300.000000   \n",
       "mean                 0.992233            0.996509    0.997720   \n",
       "std                  0.006893            0.004117    0.002740   \n",
       "min                  0.962264            0.981132    0.990566   \n",
       "25%                  0.990566            0.995283    0.995283   \n",
       "50%                  0.995283            0.995283    1.000000   \n",
       "75%                  0.995283            1.000000    1.000000   \n",
       "max                  1.000000            1.000000    1.000000   \n",
       "\n",
       "       LogisticRegression  \n",
       "count          300.000000  \n",
       "mean             0.998113  \n",
       "std              0.002700  \n",
       "min              0.990566  \n",
       "25%              0.995283  \n",
       "50%              1.000000  \n",
       "75%              1.000000  \n",
       "max              1.000000  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_score_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "bf0d6a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LogisticRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.541628</td>\n",
       "      <td>1.793851</td>\n",
       "      <td>0.053746</td>\n",
       "      <td>0.021782</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.014169</td>\n",
       "      <td>0.029495</td>\n",
       "      <td>0.002660</td>\n",
       "      <td>0.002718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.513627</td>\n",
       "      <td>1.769270</td>\n",
       "      <td>0.048868</td>\n",
       "      <td>0.017951</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.534321</td>\n",
       "      <td>1.780241</td>\n",
       "      <td>0.051862</td>\n",
       "      <td>0.020694</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.540056</td>\n",
       "      <td>1.786225</td>\n",
       "      <td>0.053855</td>\n",
       "      <td>0.020945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.546538</td>\n",
       "      <td>1.795201</td>\n",
       "      <td>0.054853</td>\n",
       "      <td>0.021942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.644278</td>\n",
       "      <td>2.026583</td>\n",
       "      <td>0.072805</td>\n",
       "      <td>0.040892</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RandomForestClassifier  AdaBoostClassifier         SVC  \\\n",
       "count              300.000000          300.000000  300.000000   \n",
       "mean                 0.541628            1.793851    0.053746   \n",
       "std                  0.014169            0.029495    0.002660   \n",
       "min                  0.513627            1.769270    0.048868   \n",
       "25%                  0.534321            1.780241    0.051862   \n",
       "50%                  0.540056            1.786225    0.053855   \n",
       "75%                  0.546538            1.795201    0.054853   \n",
       "max                  0.644278            2.026583    0.072805   \n",
       "\n",
       "       LogisticRegression  \n",
       "count          300.000000  \n",
       "mean             0.021782  \n",
       "std              0.002718  \n",
       "min              0.017951  \n",
       "25%              0.020694  \n",
       "50%              0.020945  \n",
       "75%              0.021942  \n",
       "max              0.040892  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timing_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5175a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimators_repeater2(estimators=[RandomForestClassifier(),AdaBoostClassifier(),SVC()],tr_slicer=(None,None),tst_slicer=(None,None),loops=300,scorer=recall_score,x=x,y=y):\n",
    "    training_score={}\n",
    "    testing_score={}\n",
    "    timing={}\n",
    "    for cl in estimators:\n",
    "        cl_name=cl.__class__.__name__\n",
    "        training_score[cl_name]=[]\n",
    "        testing_score[cl_name]=[]\n",
    "        timing[cl_name]=[]\n",
    "    for i in range(loops):\n",
    "        k1=time()\n",
    "        x_train, x_test, y_train, y_test=train_test_split(x,y,random_state=i)\n",
    "        for cl in estimators:\n",
    "            a=time()\n",
    "            cl_name=cl.__class__.__name__\n",
    "            clean_cl=clone(cl)\n",
    "            clean_cl.fit(x_train[tr_slicer[0]:tr_slicer[1]],y_train[tr_slicer[0]:tr_slicer[1]])\n",
    "            training_score[cl_name].append(scorer(y_train[tr_slicer[0]:tr_slicer[1]],clean_cl.predict(x_train[tr_slicer[0]:tr_slicer[1]])))\n",
    "            testing_score[cl_name].append(scorer(y_test[tst_slicer[0]:tst_slicer[1]],clean_cl.predict(x_test[tst_slicer[0]:tst_slicer[1]])))\n",
    "            b=time()                                \n",
    "            timing[cl_name].append(b-a)\n",
    "        k2=time()\n",
    "        print(f'number {i} out of {loops} took {k2-k1} seconds')\n",
    "    global training_score_df\n",
    "    training_score_df=pd.DataFrame(training_score)\n",
    "    global testing_score_df\n",
    "    testing_score_df=pd.DataFrame(testing_score)\n",
    "    global timing_df\n",
    "    timing_df=pd.DataFrame(timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e58c58ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 0 out of 300 took 2.4095571041107178 seconds\n",
      "number 1 out of 300 took 2.404571294784546 seconds\n",
      "number 2 out of 300 took 2.419532060623169 seconds\n",
      "number 3 out of 300 took 2.4135470390319824 seconds\n",
      "number 4 out of 300 took 2.412551164627075 seconds\n",
      "number 5 out of 300 took 2.3926031589508057 seconds\n",
      "number 6 out of 300 took 2.442469835281372 seconds\n",
      "number 7 out of 300 took 2.449450731277466 seconds\n",
      "number 8 out of 300 took 2.391605854034424 seconds\n",
      "number 9 out of 300 took 2.4135475158691406 seconds\n",
      "number 10 out of 300 took 2.409557580947876 seconds\n",
      "number 11 out of 300 took 2.424518585205078 seconds\n",
      "number 12 out of 300 took 2.4065659046173096 seconds\n",
      "number 13 out of 300 took 2.405568838119507 seconds\n",
      "number 14 out of 300 took 2.42850661277771 seconds\n",
      "number 15 out of 300 took 2.404572010040283 seconds\n",
      "number 16 out of 300 took 2.409558057785034 seconds\n",
      "number 17 out of 300 took 2.405569553375244 seconds\n",
      "number 18 out of 300 took 2.420527935028076 seconds\n",
      "number 19 out of 300 took 2.422523260116577 seconds\n",
      "number 20 out of 300 took 2.408560276031494 seconds\n",
      "number 21 out of 300 took 2.3955955505371094 seconds\n",
      "number 22 out of 300 took 2.417536497116089 seconds\n",
      "number 23 out of 300 took 2.4085609912872314 seconds\n",
      "number 24 out of 300 took 2.4215261936187744 seconds\n",
      "number 25 out of 300 took 2.403573513031006 seconds\n",
      "number 26 out of 300 took 2.4035747051239014 seconds\n",
      "number 27 out of 300 took 2.4205281734466553 seconds\n",
      "number 28 out of 300 took 2.4205288887023926 seconds\n",
      "number 29 out of 300 took 2.3955960273742676 seconds\n",
      "number 30 out of 300 took 2.402576208114624 seconds\n",
      "number 31 out of 300 took 2.4255154132843018 seconds\n",
      "number 32 out of 300 took 2.4135472774505615 seconds\n",
      "number 33 out of 300 took 2.406566619873047 seconds\n",
      "number 34 out of 300 took 2.409558057785034 seconds\n",
      "number 35 out of 300 took 2.410555362701416 seconds\n",
      "number 36 out of 300 took 2.422522783279419 seconds\n",
      "number 37 out of 300 took 2.3876166343688965 seconds\n",
      "number 38 out of 300 took 2.4125499725341797 seconds\n",
      "number 39 out of 300 took 2.397589921951294 seconds\n",
      "number 40 out of 300 took 2.4025769233703613 seconds\n",
      "number 41 out of 300 took 2.3995847702026367 seconds\n",
      "number 42 out of 300 took 2.4155423641204834 seconds\n",
      "number 43 out of 300 took 2.421525239944458 seconds\n",
      "number 44 out of 300 took 2.4005823135375977 seconds\n",
      "number 45 out of 300 took 2.427510976791382 seconds\n",
      "number 46 out of 300 took 2.3926026821136475 seconds\n",
      "number 47 out of 300 took 2.417536497116089 seconds\n",
      "number 48 out of 300 took 2.4145443439483643 seconds\n",
      "number 49 out of 300 took 2.3916070461273193 seconds\n",
      "number 50 out of 300 took 2.415541887283325 seconds\n",
      "number 51 out of 300 took 2.3846254348754883 seconds\n",
      "number 52 out of 300 took 2.4444644451141357 seconds\n",
      "number 53 out of 300 took 2.4155430793762207 seconds\n",
      "number 54 out of 300 took 2.4055683612823486 seconds\n",
      "number 55 out of 300 took 2.4195315837860107 seconds\n",
      "number 56 out of 300 took 2.404571056365967 seconds\n",
      "number 57 out of 300 took 2.408560276031494 seconds\n",
      "number 58 out of 300 took 2.4295053482055664 seconds\n",
      "number 59 out of 300 took 2.3965930938720703 seconds\n",
      "number 60 out of 300 took 2.4115524291992188 seconds\n",
      "number 61 out of 300 took 2.3886144161224365 seconds\n",
      "number 62 out of 300 took 2.4115514755249023 seconds\n",
      "number 63 out of 300 took 2.4215269088745117 seconds\n",
      "number 64 out of 300 took 2.421525478363037 seconds\n",
      "number 65 out of 300 took 2.400580883026123 seconds\n",
      "number 66 out of 300 took 2.409558057785034 seconds\n",
      "number 67 out of 300 took 2.4075636863708496 seconds\n",
      "number 68 out of 300 took 2.391605854034424 seconds\n",
      "number 69 out of 300 took 2.4055685997009277 seconds\n",
      "number 70 out of 300 took 2.4145452976226807 seconds\n",
      "number 71 out of 300 took 2.4125494956970215 seconds\n",
      "number 72 out of 300 took 2.444464683532715 seconds\n",
      "number 73 out of 300 took 2.391606092453003 seconds\n",
      "number 74 out of 300 took 2.4145450592041016 seconds\n",
      "number 75 out of 300 took 2.4005813598632812 seconds\n",
      "number 76 out of 300 took 2.3896124362945557 seconds\n",
      "number 77 out of 300 took 2.429504632949829 seconds\n",
      "number 78 out of 300 took 2.404571294784546 seconds\n",
      "number 79 out of 300 took 2.4245169162750244 seconds\n",
      "number 80 out of 300 took 2.4005823135375977 seconds\n",
      "number 81 out of 300 took 2.432497024536133 seconds\n",
      "number 82 out of 300 took 2.4015796184539795 seconds\n",
      "number 83 out of 300 took 2.396592855453491 seconds\n",
      "number 84 out of 300 took 2.41853404045105 seconds\n",
      "number 85 out of 300 took 2.4145445823669434 seconds\n",
      "number 86 out of 300 took 2.405569314956665 seconds\n",
      "number 87 out of 300 took 2.4055676460266113 seconds\n",
      "number 88 out of 300 took 2.4065663814544678 seconds\n",
      "number 89 out of 300 took 2.4314992427825928 seconds\n",
      "number 90 out of 300 took 2.3806354999542236 seconds\n",
      "number 91 out of 300 took 2.4275104999542236 seconds\n",
      "number 92 out of 300 took 2.4145443439483643 seconds\n",
      "number 93 out of 300 took 2.3995842933654785 seconds\n",
      "number 94 out of 300 took 2.3906078338623047 seconds\n",
      "number 95 out of 300 took 2.4155426025390625 seconds\n",
      "number 96 out of 300 took 2.4165384769439697 seconds\n",
      "number 97 out of 300 took 2.412551164627075 seconds\n",
      "number 98 out of 300 took 2.399583578109741 seconds\n",
      "number 99 out of 300 took 2.397590398788452 seconds\n",
      "number 100 out of 300 took 2.432497262954712 seconds\n",
      "number 101 out of 300 took 2.4195313453674316 seconds\n",
      "number 102 out of 300 took 2.4225239753723145 seconds\n",
      "number 103 out of 300 took 2.398587942123413 seconds\n",
      "number 104 out of 300 took 2.396592617034912 seconds\n",
      "number 105 out of 300 took 2.4205284118652344 seconds\n",
      "number 106 out of 300 took 2.430502414703369 seconds\n",
      "number 107 out of 300 took 2.3936007022857666 seconds\n",
      "number 108 out of 300 took 2.4195315837860107 seconds\n",
      "number 109 out of 300 took 2.421525478363037 seconds\n",
      "number 110 out of 300 took 2.406566619873047 seconds\n",
      "number 111 out of 300 took 2.416538953781128 seconds\n",
      "number 112 out of 300 took 2.391606569290161 seconds\n",
      "number 113 out of 300 took 2.4275100231170654 seconds\n",
      "number 114 out of 300 took 2.3985867500305176 seconds\n",
      "number 115 out of 300 took 2.414546012878418 seconds\n",
      "number 116 out of 300 took 2.400583028793335 seconds\n",
      "number 117 out of 300 took 2.408560276031494 seconds\n",
      "number 118 out of 300 took 2.4384799003601074 seconds\n",
      "number 119 out of 300 took 2.4015793800354004 seconds\n",
      "number 120 out of 300 took 2.4205284118652344 seconds\n",
      "number 121 out of 300 took 2.4005820751190186 seconds\n",
      "number 122 out of 300 took 2.4095587730407715 seconds\n",
      "number 123 out of 300 took 2.4075634479522705 seconds\n",
      "number 124 out of 300 took 2.3955953121185303 seconds\n",
      "number 125 out of 300 took 2.422523260116577 seconds\n",
      "number 126 out of 300 took 2.418534278869629 seconds\n",
      "number 127 out of 300 took 2.4464592933654785 seconds\n",
      "number 128 out of 300 took 2.4205286502838135 seconds\n",
      "number 129 out of 300 took 2.4015798568725586 seconds\n",
      "number 130 out of 300 took 2.42052960395813 seconds\n",
      "number 131 out of 300 took 2.4065659046173096 seconds\n",
      "number 132 out of 300 took 2.427511215209961 seconds\n",
      "number 133 out of 300 took 2.3936004638671875 seconds\n",
      "number 134 out of 300 took 2.417536973953247 seconds\n",
      "number 135 out of 300 took 2.4265127182006836 seconds\n",
      "number 136 out of 300 took 2.4095582962036133 seconds\n",
      "number 137 out of 300 took 2.4055676460266113 seconds\n",
      "number 138 out of 300 took 2.4095582962036133 seconds\n",
      "number 139 out of 300 took 2.443467378616333 seconds\n",
      "number 140 out of 300 took 2.4364867210388184 seconds\n",
      "number 141 out of 300 took 2.502309799194336 seconds\n",
      "number 142 out of 300 took 2.4674031734466553 seconds\n",
      "number 143 out of 300 took 2.4354894161224365 seconds\n",
      "number 144 out of 300 took 2.408560037612915 seconds\n",
      "number 145 out of 300 took 2.3936007022857666 seconds\n",
      "number 146 out of 300 took 2.4235198497772217 seconds\n",
      "number 147 out of 300 took 2.4324967861175537 seconds\n",
      "number 148 out of 300 took 2.404571056365967 seconds\n",
      "number 149 out of 300 took 2.3985884189605713 seconds\n",
      "number 150 out of 300 took 2.3995845317840576 seconds\n",
      "number 151 out of 300 took 2.3995840549468994 seconds\n",
      "number 152 out of 300 took 2.403574228286743 seconds\n",
      "number 153 out of 300 took 2.423520803451538 seconds\n",
      "number 154 out of 300 took 2.4185338020324707 seconds\n",
      "number 155 out of 300 took 2.4005818367004395 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 156 out of 300 took 2.4205286502838135 seconds\n",
      "number 157 out of 300 took 2.3926026821136475 seconds\n",
      "number 158 out of 300 took 2.417537212371826 seconds\n",
      "number 159 out of 300 took 2.3816323280334473 seconds\n",
      "number 160 out of 300 took 2.409557819366455 seconds\n",
      "number 161 out of 300 took 2.4135472774505615 seconds\n",
      "number 162 out of 300 took 2.405568838119507 seconds\n",
      "number 163 out of 300 took 2.4035754203796387 seconds\n",
      "number 164 out of 300 took 2.404571056365967 seconds\n",
      "number 165 out of 300 took 2.4275104999542236 seconds\n",
      "number 166 out of 300 took 2.419529914855957 seconds\n",
      "number 167 out of 300 took 2.4005825519561768 seconds\n",
      "number 168 out of 300 took 2.4105546474456787 seconds\n",
      "number 169 out of 300 took 2.3995847702026367 seconds\n",
      "number 170 out of 300 took 2.4215259552001953 seconds\n",
      "number 171 out of 300 took 2.419532299041748 seconds\n",
      "number 172 out of 300 took 2.432495355606079 seconds\n",
      "number 173 out of 300 took 2.3975894451141357 seconds\n",
      "number 174 out of 300 took 2.420527935028076 seconds\n",
      "number 175 out of 300 took 2.4315006732940674 seconds\n",
      "number 176 out of 300 took 2.4025769233703613 seconds\n",
      "number 177 out of 300 took 2.423520803451538 seconds\n",
      "number 178 out of 300 took 2.384624719619751 seconds\n",
      "number 179 out of 300 took 2.3776423931121826 seconds\n",
      "number 180 out of 300 took 2.404571771621704 seconds\n",
      "number 181 out of 300 took 2.4105546474456787 seconds\n",
      "number 182 out of 300 took 2.410554885864258 seconds\n",
      "number 183 out of 300 took 2.4025771617889404 seconds\n",
      "number 184 out of 300 took 2.4095590114593506 seconds\n",
      "number 185 out of 300 took 2.4195315837860107 seconds\n",
      "number 186 out of 300 took 2.3926029205322266 seconds\n",
      "number 187 out of 300 took 2.4205286502838135 seconds\n",
      "number 188 out of 300 took 2.396592378616333 seconds\n",
      "number 189 out of 300 took 2.405569076538086 seconds\n",
      "number 190 out of 300 took 2.418534278869629 seconds\n",
      "number 191 out of 300 took 2.3945982456207275 seconds\n",
      "number 192 out of 300 took 2.421525001525879 seconds\n",
      "number 193 out of 300 took 2.397590398788452 seconds\n",
      "number 194 out of 300 took 2.407562494277954 seconds\n",
      "number 195 out of 300 took 2.419532299041748 seconds\n",
      "number 196 out of 300 took 2.3995847702026367 seconds\n",
      "number 197 out of 300 took 2.43648624420166 seconds\n",
      "number 198 out of 300 took 2.4314987659454346 seconds\n",
      "number 199 out of 300 took 2.4474573135375977 seconds\n",
      "number 200 out of 300 took 2.4664056301116943 seconds\n",
      "number 201 out of 300 took 2.408560276031494 seconds\n",
      "number 202 out of 300 took 2.4275107383728027 seconds\n",
      "number 203 out of 300 took 2.402576208114624 seconds\n",
      "number 204 out of 300 took 2.4205286502838135 seconds\n",
      "number 205 out of 300 took 2.4095587730407715 seconds\n",
      "number 206 out of 300 took 2.3866193294525146 seconds\n",
      "number 207 out of 300 took 2.421527147293091 seconds\n",
      "number 208 out of 300 took 2.3985862731933594 seconds\n",
      "number 209 out of 300 took 2.406567096710205 seconds\n",
      "number 210 out of 300 took 2.404571056365967 seconds\n",
      "number 211 out of 300 took 2.410555839538574 seconds\n",
      "number 212 out of 300 took 2.395594358444214 seconds\n",
      "number 213 out of 300 took 2.3975911140441895 seconds\n",
      "number 214 out of 300 took 2.420527696609497 seconds\n",
      "number 215 out of 300 took 2.3985869884490967 seconds\n",
      "number 216 out of 300 took 2.411553382873535 seconds\n",
      "number 217 out of 300 took 2.396592855453491 seconds\n",
      "number 218 out of 300 took 2.421525716781616 seconds\n",
      "number 219 out of 300 took 2.418534278869629 seconds\n",
      "number 220 out of 300 took 2.417537212371826 seconds\n",
      "number 221 out of 300 took 2.423520565032959 seconds\n",
      "number 222 out of 300 took 2.411553144454956 seconds\n",
      "number 223 out of 300 took 2.4344913959503174 seconds\n",
      "number 224 out of 300 took 2.410554885864258 seconds\n",
      "number 225 out of 300 took 2.431499481201172 seconds\n",
      "number 226 out of 300 took 2.4185338020324707 seconds\n",
      "number 227 out of 300 took 2.410555839538574 seconds\n",
      "number 228 out of 300 took 2.423520565032959 seconds\n",
      "number 229 out of 300 took 2.410554885864258 seconds\n",
      "number 230 out of 300 took 2.4085609912872314 seconds\n",
      "number 231 out of 300 took 2.4135475158691406 seconds\n",
      "number 232 out of 300 took 2.397589921951294 seconds\n",
      "number 233 out of 300 took 2.3945982456207275 seconds\n",
      "number 234 out of 300 took 2.4015791416168213 seconds\n",
      "number 235 out of 300 took 2.4334943294525146 seconds\n",
      "number 236 out of 300 took 2.3945977687835693 seconds\n",
      "number 237 out of 300 took 2.426513433456421 seconds\n",
      "number 238 out of 300 took 2.408559799194336 seconds\n",
      "number 239 out of 300 took 2.4025774002075195 seconds\n",
      "number 240 out of 300 took 2.4125497341156006 seconds\n",
      "number 241 out of 300 took 2.394597291946411 seconds\n",
      "number 242 out of 300 took 2.400582790374756 seconds\n",
      "number 243 out of 300 took 2.408559799194336 seconds\n",
      "number 244 out of 300 took 2.3896119594573975 seconds\n",
      "number 245 out of 300 took 2.402575969696045 seconds\n",
      "number 246 out of 300 took 2.3916068077087402 seconds\n",
      "number 247 out of 300 took 2.4275100231170654 seconds\n",
      "number 248 out of 300 took 2.421525716781616 seconds\n",
      "number 249 out of 300 took 2.422523021697998 seconds\n",
      "number 250 out of 300 took 2.431499481201172 seconds\n",
      "number 251 out of 300 took 2.4045722484588623 seconds\n",
      "number 252 out of 300 took 2.4334936141967773 seconds\n",
      "number 253 out of 300 took 2.3945982456207275 seconds\n",
      "number 254 out of 300 took 2.4085605144500732 seconds\n",
      "number 255 out of 300 took 2.397589921951294 seconds\n",
      "number 256 out of 300 took 2.4035751819610596 seconds\n",
      "number 257 out of 300 took 2.409558057785034 seconds\n",
      "number 258 out of 300 took 2.4005823135375977 seconds\n",
      "number 259 out of 300 took 2.409557580947876 seconds\n",
      "number 260 out of 300 took 2.3886139392852783 seconds\n",
      "number 261 out of 300 took 2.408559799194336 seconds\n",
      "number 262 out of 300 took 2.410555601119995 seconds\n",
      "number 263 out of 300 took 2.3896114826202393 seconds\n",
      "number 264 out of 300 took 2.4354889392852783 seconds\n",
      "number 265 out of 300 took 2.395594835281372 seconds\n",
      "number 266 out of 300 took 2.4085605144500732 seconds\n",
      "number 267 out of 300 took 2.398587942123413 seconds\n",
      "number 268 out of 300 took 2.421525478363037 seconds\n",
      "number 269 out of 300 took 2.3945980072021484 seconds\n",
      "number 270 out of 300 took 2.3866195678710938 seconds\n",
      "number 271 out of 300 took 2.421525478363037 seconds\n",
      "number 272 out of 300 took 2.3906095027923584 seconds\n",
      "number 273 out of 300 took 2.4245171546936035 seconds\n",
      "number 274 out of 300 took 2.4195311069488525 seconds\n",
      "number 275 out of 300 took 2.4075639247894287 seconds\n",
      "number 276 out of 300 took 2.416538715362549 seconds\n",
      "number 277 out of 300 took 2.4414727687835693 seconds\n",
      "number 278 out of 300 took 2.4235217571258545 seconds\n",
      "number 279 out of 300 took 2.4105541706085205 seconds\n",
      "number 280 out of 300 took 2.3995845317840576 seconds\n",
      "number 281 out of 300 took 2.418534517288208 seconds\n",
      "number 282 out of 300 took 2.410555362701416 seconds\n",
      "number 283 out of 300 took 2.42551589012146 seconds\n",
      "number 284 out of 300 took 2.3916070461273193 seconds\n",
      "number 285 out of 300 took 2.416538715362549 seconds\n",
      "number 286 out of 300 took 2.393601179122925 seconds\n",
      "number 287 out of 300 took 2.4155426025390625 seconds\n",
      "number 288 out of 300 took 2.401578903198242 seconds\n",
      "number 289 out of 300 took 2.4095585346221924 seconds\n",
      "number 290 out of 300 took 2.493333339691162 seconds\n",
      "number 291 out of 300 took 2.43149995803833 seconds\n",
      "number 292 out of 300 took 2.402576208114624 seconds\n",
      "number 293 out of 300 took 2.416538715362549 seconds\n",
      "number 294 out of 300 took 2.397590398788452 seconds\n",
      "number 295 out of 300 took 2.4205284118652344 seconds\n",
      "number 296 out of 300 took 2.4295051097869873 seconds\n",
      "number 297 out of 300 took 2.4195308685302734 seconds\n",
      "number 298 out of 300 took 2.410555601119995 seconds\n",
      "number 299 out of 300 took 2.3975906372070312 seconds\n"
     ]
    }
   ],
   "source": [
    "estimators_repeater2(estimators=[RandomForestClassifier(),AdaBoostClassifier(),SVC(),LogisticRegression()],x=x,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f45fe35b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LogisticRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.0</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.995191</td>\n",
       "      <td>0.995331</td>\n",
       "      <td>0.996112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.006282</td>\n",
       "      <td>0.005646</td>\n",
       "      <td>0.005560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>0.979167</td>\n",
       "      <td>0.979167</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.990361</td>\n",
       "      <td>0.990385</td>\n",
       "      <td>0.990476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RandomForestClassifier  AdaBoostClassifier         SVC  \\\n",
       "count                   300.0          300.000000  300.000000   \n",
       "mean                      1.0            0.995191    0.995331   \n",
       "std                       0.0            0.006282    0.005646   \n",
       "min                       1.0            0.958333    0.979167   \n",
       "25%                       1.0            0.990361    0.990385   \n",
       "50%                       1.0            1.000000    1.000000   \n",
       "75%                       1.0            1.000000    1.000000   \n",
       "max                       1.0            1.000000    1.000000   \n",
       "\n",
       "       LogisticRegression  \n",
       "count          300.000000  \n",
       "mean             0.996112  \n",
       "std              0.005560  \n",
       "min              0.979167  \n",
       "25%              0.990476  \n",
       "50%              1.000000  \n",
       "75%              1.000000  \n",
       "max              1.000000  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_score_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd10eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
