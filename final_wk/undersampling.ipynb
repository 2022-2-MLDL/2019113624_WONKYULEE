{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "114891af",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score \n",
    "from sklearn.base import clone\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a9cecb2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('final_df2.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7d231150",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.iloc[:, :-1]\n",
    "y = df.iloc[:, -1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2cff4e1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ELMO2</th>\n",
       "      <th>CREB3L1</th>\n",
       "      <th>RPS11</th>\n",
       "      <th>PNMA1</th>\n",
       "      <th>MMP2</th>\n",
       "      <th>C10orf90</th>\n",
       "      <th>ZHX3</th>\n",
       "      <th>ERCC5</th>\n",
       "      <th>GPR98</th>\n",
       "      <th>RXFP3</th>\n",
       "      <th>...</th>\n",
       "      <th>SLC2A11</th>\n",
       "      <th>GRIP2</th>\n",
       "      <th>GPLD1</th>\n",
       "      <th>RAB8A</th>\n",
       "      <th>RXFP2</th>\n",
       "      <th>PIK3IP1</th>\n",
       "      <th>SLC39A6</th>\n",
       "      <th>SNRPD2</th>\n",
       "      <th>AQP7</th>\n",
       "      <th>CTSC</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.886827</td>\n",
       "      <td>0.349044</td>\n",
       "      <td>0.159261</td>\n",
       "      <td>-1.586876</td>\n",
       "      <td>-0.783517</td>\n",
       "      <td>-0.651792</td>\n",
       "      <td>-0.192552</td>\n",
       "      <td>-0.688943</td>\n",
       "      <td>1.790315</td>\n",
       "      <td>0.606942</td>\n",
       "      <td>...</td>\n",
       "      <td>0.618291</td>\n",
       "      <td>-0.244858</td>\n",
       "      <td>0.087421</td>\n",
       "      <td>-0.441970</td>\n",
       "      <td>0.805609</td>\n",
       "      <td>0.084007</td>\n",
       "      <td>-0.853409</td>\n",
       "      <td>-0.767943</td>\n",
       "      <td>-0.097567</td>\n",
       "      <td>0.208945</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.076357</td>\n",
       "      <td>0.902533</td>\n",
       "      <td>0.026440</td>\n",
       "      <td>1.624105</td>\n",
       "      <td>1.396133</td>\n",
       "      <td>0.195322</td>\n",
       "      <td>0.394281</td>\n",
       "      <td>0.733565</td>\n",
       "      <td>1.460883</td>\n",
       "      <td>-0.288978</td>\n",
       "      <td>...</td>\n",
       "      <td>0.083736</td>\n",
       "      <td>-0.957388</td>\n",
       "      <td>0.095699</td>\n",
       "      <td>0.972672</td>\n",
       "      <td>0.691112</td>\n",
       "      <td>1.004964</td>\n",
       "      <td>-0.178898</td>\n",
       "      <td>-0.945141</td>\n",
       "      <td>0.843130</td>\n",
       "      <td>-1.062326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.160544</td>\n",
       "      <td>0.875732</td>\n",
       "      <td>4.027129</td>\n",
       "      <td>0.072768</td>\n",
       "      <td>0.488563</td>\n",
       "      <td>-0.707819</td>\n",
       "      <td>-1.258655</td>\n",
       "      <td>2.353938</td>\n",
       "      <td>1.514641</td>\n",
       "      <td>-0.194159</td>\n",
       "      <td>...</td>\n",
       "      <td>0.561794</td>\n",
       "      <td>-0.680456</td>\n",
       "      <td>-0.348212</td>\n",
       "      <td>0.766775</td>\n",
       "      <td>-0.167253</td>\n",
       "      <td>0.878351</td>\n",
       "      <td>1.027238</td>\n",
       "      <td>-0.487267</td>\n",
       "      <td>0.630930</td>\n",
       "      <td>-0.273803</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.093755</td>\n",
       "      <td>0.023215</td>\n",
       "      <td>-1.310286</td>\n",
       "      <td>0.819120</td>\n",
       "      <td>-0.815949</td>\n",
       "      <td>-0.407544</td>\n",
       "      <td>0.793497</td>\n",
       "      <td>-0.158602</td>\n",
       "      <td>-0.161729</td>\n",
       "      <td>1.060372</td>\n",
       "      <td>...</td>\n",
       "      <td>2.103530</td>\n",
       "      <td>-1.246807</td>\n",
       "      <td>-1.676863</td>\n",
       "      <td>0.213831</td>\n",
       "      <td>-1.585708</td>\n",
       "      <td>0.933448</td>\n",
       "      <td>0.740015</td>\n",
       "      <td>-1.050423</td>\n",
       "      <td>-0.987469</td>\n",
       "      <td>-0.644158</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.249586</td>\n",
       "      <td>-0.633865</td>\n",
       "      <td>-0.325074</td>\n",
       "      <td>0.155425</td>\n",
       "      <td>0.019339</td>\n",
       "      <td>-0.462644</td>\n",
       "      <td>-0.576603</td>\n",
       "      <td>-1.569976</td>\n",
       "      <td>-1.943742</td>\n",
       "      <td>0.022223</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.478282</td>\n",
       "      <td>0.569776</td>\n",
       "      <td>-0.794047</td>\n",
       "      <td>-0.079013</td>\n",
       "      <td>0.559841</td>\n",
       "      <td>-0.793164</td>\n",
       "      <td>-1.567624</td>\n",
       "      <td>0.733505</td>\n",
       "      <td>-0.957059</td>\n",
       "      <td>0.428773</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 17814 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      ELMO2   CREB3L1     RPS11     PNMA1      MMP2  C10orf90      ZHX3  \\\n",
       "0  0.886827  0.349044  0.159261 -1.586876 -0.783517 -0.651792 -0.192552   \n",
       "1 -0.076357  0.902533  0.026440  1.624105  1.396133  0.195322  0.394281   \n",
       "2  1.160544  0.875732  4.027129  0.072768  0.488563 -0.707819 -1.258655   \n",
       "3 -0.093755  0.023215 -1.310286  0.819120 -0.815949 -0.407544  0.793497   \n",
       "4 -0.249586 -0.633865 -0.325074  0.155425  0.019339 -0.462644 -0.576603   \n",
       "\n",
       "      ERCC5     GPR98     RXFP3  ...   SLC2A11     GRIP2     GPLD1     RAB8A  \\\n",
       "0 -0.688943  1.790315  0.606942  ...  0.618291 -0.244858  0.087421 -0.441970   \n",
       "1  0.733565  1.460883 -0.288978  ...  0.083736 -0.957388  0.095699  0.972672   \n",
       "2  2.353938  1.514641 -0.194159  ...  0.561794 -0.680456 -0.348212  0.766775   \n",
       "3 -0.158602 -0.161729  1.060372  ...  2.103530 -1.246807 -1.676863  0.213831   \n",
       "4 -1.569976 -1.943742  0.022223  ... -1.478282  0.569776 -0.794047 -0.079013   \n",
       "\n",
       "      RXFP2   PIK3IP1   SLC39A6    SNRPD2      AQP7      CTSC  \n",
       "0  0.805609  0.084007 -0.853409 -0.767943 -0.097567  0.208945  \n",
       "1  0.691112  1.004964 -0.178898 -0.945141  0.843130 -1.062326  \n",
       "2 -0.167253  0.878351  1.027238 -0.487267  0.630930 -0.273803  \n",
       "3 -1.585708  0.933448  0.740015 -1.050423 -0.987469 -0.644158  \n",
       "4  0.559841 -0.793164 -1.567624  0.733505 -0.957059  0.428773  \n",
       "\n",
       "[5 rows x 17814 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "std_df = StandardScaler().fit_transform(X)\n",
    "std_df = pd.DataFrame(std_df, index=X.index, columns=X.columns)\n",
    "df2 = std_df\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1bb704b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn\n",
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "X_train, y_train = RandomUnderSampler(random_state=2021).fit_resample(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4eda2e3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "undersampling 적용 전 학습용 피처/레이블 데이터 세트 :  (590, 17814) (590,)\n",
      "undersampling 적용 후 학습용 피처/레이블 데이터 세트 : (122, 17814) (122,)\n",
      "undersampling 적용 후 값의 분포 :\n",
      " 0    61\n",
      "1    61\n",
      "Name: label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"undersampling 적용 전 학습용 피처/레이블 데이터 세트 : \", X.shape, y.shape)\n",
    "print('undersampling 적용 후 학습용 피처/레이블 데이터 세트 :', X_train.shape, y_train.shape)\n",
    "print('undersampling 적용 후 값의 분포 :\\n',pd.Series(y_train).value_counts() )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8e177437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=109)\n",
    "pca_array = pca.fit_transform(X_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2fdcb3c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA()\n",
    "pca.fit(X_train)\n",
    "cumsum = np.cumsum(pca.explained_variance_ratio_)\n",
    "# 주성분의 개수를 지정하지 않고 찾아줌\n",
    "# 분산의 비율을 누적해서 더한 값이 95% 이상인 주성분의 개수\n",
    "# 즉, 분산의 95%이상 유지\n",
    "d = np.argmax(cumsum >= 0.99) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "df171715",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "109"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b5d9475f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(122, 109)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dec=PCA(0.99)\n",
    "x2=dec.fit_transform(X_train)\n",
    "x2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "952fc1c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "x, x_test, y, y_test=train_test_split(pca_array,y_train,test_size= 0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "232e75ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimators_repeater(estimators=[RandomForestClassifier(),AdaBoostClassifier(),SVC()],tr_slicer=(None,None),tst_slicer=(None,None),loops=300,scorer=accuracy_score,x=x,y=y):\n",
    "    training_score={}\n",
    "    testing_score={}\n",
    "    timing={}\n",
    "    for cl in estimators:\n",
    "        cl_name=cl.__class__.__name__\n",
    "        training_score[cl_name]=[]\n",
    "        testing_score[cl_name]=[]\n",
    "        timing[cl_name]=[]\n",
    "    for i in range(loops):\n",
    "        k1=time()\n",
    "        x_train, x_test, y_train, y_test=train_test_split(x,y,random_state=i)\n",
    "        for cl in estimators:\n",
    "            a=time()\n",
    "            cl_name=cl.__class__.__name__\n",
    "            clean_cl=clone(cl)\n",
    "            clean_cl.fit(x_train[tr_slicer[0]:tr_slicer[1]],y_train[tr_slicer[0]:tr_slicer[1]])\n",
    "            training_score[cl_name].append(scorer(y_train[tr_slicer[0]:tr_slicer[1]],clean_cl.predict(x_train[tr_slicer[0]:tr_slicer[1]])))\n",
    "            testing_score[cl_name].append(scorer(y_test[tst_slicer[0]:tst_slicer[1]],clean_cl.predict(x_test[tst_slicer[0]:tst_slicer[1]])))\n",
    "            b=time()                                \n",
    "            timing[cl_name].append(b-a)\n",
    "        k2=time()\n",
    "        print(f'number {i} out of {loops} took {k2-k1} seconds')\n",
    "    global training_score_df\n",
    "    training_score_df=pd.DataFrame(training_score)\n",
    "    global testing_score_df\n",
    "    testing_score_df=pd.DataFrame(testing_score)\n",
    "    global timing_df\n",
    "    timing_df=pd.DataFrame(timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "80c99c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 0 out of 300 took 0.2902224063873291 seconds\n",
      "number 1 out of 300 took 0.2862358093261719 seconds\n",
      "number 2 out of 300 took 0.29421257972717285 seconds\n",
      "number 3 out of 300 took 0.1765291690826416 seconds\n",
      "number 4 out of 300 took 0.2822456359863281 seconds\n",
      "number 5 out of 300 took 0.2812466621398926 seconds\n",
      "number 6 out of 300 took 0.28623509407043457 seconds\n",
      "number 7 out of 300 took 0.16655468940734863 seconds\n",
      "number 8 out of 300 took 0.2812483310699463 seconds\n",
      "number 9 out of 300 took 0.27725863456726074 seconds\n",
      "number 10 out of 300 took 0.2752649784088135 seconds\n",
      "number 11 out of 300 took 0.27725815773010254 seconds\n",
      "number 12 out of 300 took 0.2782564163208008 seconds\n",
      "number 13 out of 300 took 0.2812490463256836 seconds\n",
      "number 14 out of 300 took 0.2712740898132324 seconds\n",
      "number 15 out of 300 took 0.28025197982788086 seconds\n",
      "number 16 out of 300 took 0.2782554626464844 seconds\n",
      "number 17 out of 300 took 0.2782559394836426 seconds\n",
      "number 18 out of 300 took 0.2782552242279053 seconds\n",
      "number 19 out of 300 took 0.2812483310699463 seconds\n",
      "number 20 out of 300 took 0.28822922706604004 seconds\n",
      "number 21 out of 300 took 0.2782552242279053 seconds\n",
      "number 22 out of 300 took 0.28025174140930176 seconds\n",
      "number 23 out of 300 took 0.2822451591491699 seconds\n",
      "number 24 out of 300 took 0.2782557010650635 seconds\n",
      "number 25 out of 300 took 0.282245397567749 seconds\n",
      "number 26 out of 300 took 0.29321718215942383 seconds\n",
      "number 27 out of 300 took 0.2822446823120117 seconds\n",
      "number 28 out of 300 took 0.28025102615356445 seconds\n",
      "number 29 out of 300 took 0.27825498580932617 seconds\n",
      "number 30 out of 300 took 0.28024983406066895 seconds\n",
      "number 31 out of 300 took 0.16954708099365234 seconds\n",
      "number 32 out of 300 took 0.1685490608215332 seconds\n",
      "number 33 out of 300 took 0.27227187156677246 seconds\n",
      "number 34 out of 300 took 0.16755294799804688 seconds\n",
      "number 35 out of 300 took 0.2782561779022217 seconds\n",
      "number 36 out of 300 took 0.2792532444000244 seconds\n",
      "number 37 out of 300 took 0.2732696533203125 seconds\n",
      "number 38 out of 300 took 0.2812478542327881 seconds\n",
      "number 39 out of 300 took 0.17054390907287598 seconds\n",
      "number 40 out of 300 took 0.168548583984375 seconds\n",
      "number 41 out of 300 took 0.2752652168273926 seconds\n",
      "number 42 out of 300 took 0.16456031799316406 seconds\n",
      "number 43 out of 300 took 0.17453217506408691 seconds\n",
      "number 44 out of 300 took 0.2782571315765381 seconds\n",
      "number 45 out of 300 took 0.2762613296508789 seconds\n",
      "number 46 out of 300 took 0.16954636573791504 seconds\n",
      "number 47 out of 300 took 0.28025054931640625 seconds\n",
      "number 48 out of 300 took 0.27725815773010254 seconds\n",
      "number 49 out of 300 took 0.2812492847442627 seconds\n",
      "number 50 out of 300 took 0.1685481071472168 seconds\n",
      "number 51 out of 300 took 0.27725958824157715 seconds\n",
      "number 52 out of 300 took 0.28025078773498535 seconds\n",
      "number 53 out of 300 took 0.27725863456726074 seconds\n",
      "number 54 out of 300 took 0.27725887298583984 seconds\n",
      "number 55 out of 300 took 0.2762618064880371 seconds\n",
      "number 56 out of 300 took 0.27825498580932617 seconds\n",
      "number 57 out of 300 took 0.27725958824157715 seconds\n",
      "number 58 out of 300 took 0.16954565048217773 seconds\n",
      "number 59 out of 300 took 0.1685495376586914 seconds\n",
      "number 60 out of 300 took 0.2752654552459717 seconds\n",
      "number 61 out of 300 took 0.27825498580932617 seconds\n",
      "number 62 out of 300 took 0.2782561779022217 seconds\n",
      "number 63 out of 300 took 0.27725934982299805 seconds\n",
      "number 64 out of 300 took 0.2822446823120117 seconds\n",
      "number 65 out of 300 took 0.2752647399902344 seconds\n",
      "number 66 out of 300 took 0.16755175590515137 seconds\n",
      "number 67 out of 300 took 0.28025007247924805 seconds\n",
      "number 68 out of 300 took 0.2792541980743408 seconds\n",
      "number 69 out of 300 took 0.27725791931152344 seconds\n",
      "number 70 out of 300 took 0.28025174140930176 seconds\n",
      "number 71 out of 300 took 0.28025150299072266 seconds\n",
      "number 72 out of 300 took 0.27825450897216797 seconds\n",
      "number 73 out of 300 took 0.27526426315307617 seconds\n",
      "number 74 out of 300 took 0.2792537212371826 seconds\n",
      "number 75 out of 300 took 0.1845076084136963 seconds\n",
      "number 76 out of 300 took 0.27725815773010254 seconds\n",
      "number 77 out of 300 took 0.2782559394836426 seconds\n",
      "number 78 out of 300 took 0.16954612731933594 seconds\n",
      "number 79 out of 300 took 0.27526402473449707 seconds\n",
      "number 80 out of 300 took 0.2752649784088135 seconds\n",
      "number 81 out of 300 took 0.27725720405578613 seconds\n",
      "number 82 out of 300 took 0.16954755783081055 seconds\n",
      "number 83 out of 300 took 0.2792527675628662 seconds\n",
      "number 84 out of 300 took 0.28025078773498535 seconds\n",
      "number 85 out of 300 took 0.2792549133300781 seconds\n",
      "number 86 out of 300 took 0.1685473918914795 seconds\n",
      "number 87 out of 300 took 0.2762625217437744 seconds\n",
      "number 88 out of 300 took 0.2762606143951416 seconds\n",
      "number 89 out of 300 took 0.279254674911499 seconds\n",
      "number 90 out of 300 took 0.17054367065429688 seconds\n",
      "number 91 out of 300 took 0.2782561779022217 seconds\n",
      "number 92 out of 300 took 0.279252290725708 seconds\n",
      "number 93 out of 300 took 0.2812478542327881 seconds\n",
      "number 94 out of 300 took 0.28025174140930176 seconds\n",
      "number 95 out of 300 took 0.17054295539855957 seconds\n",
      "number 96 out of 300 took 0.28025054931640625 seconds\n",
      "number 97 out of 300 took 0.27725934982299805 seconds\n",
      "number 98 out of 300 took 0.2782561779022217 seconds\n",
      "number 99 out of 300 took 0.16755151748657227 seconds\n",
      "number 100 out of 300 took 0.2932159900665283 seconds\n",
      "number 101 out of 300 took 0.27725887298583984 seconds\n",
      "number 102 out of 300 took 0.1685495376586914 seconds\n",
      "number 103 out of 300 took 0.17253828048706055 seconds\n",
      "number 104 out of 300 took 0.17154145240783691 seconds\n",
      "number 105 out of 300 took 0.2752654552459717 seconds\n",
      "number 106 out of 300 took 0.16954708099365234 seconds\n",
      "number 107 out of 300 took 0.27725696563720703 seconds\n",
      "number 108 out of 300 took 0.2792537212371826 seconds\n",
      "number 109 out of 300 took 0.2792537212371826 seconds\n",
      "number 110 out of 300 took 0.27526402473449707 seconds\n",
      "number 111 out of 300 took 0.1685481071472168 seconds\n",
      "number 112 out of 300 took 0.16954731941223145 seconds\n",
      "number 113 out of 300 took 0.279252290725708 seconds\n",
      "number 114 out of 300 took 0.27725982666015625 seconds\n",
      "number 115 out of 300 took 0.17054414749145508 seconds\n",
      "number 116 out of 300 took 0.17253875732421875 seconds\n",
      "number 117 out of 300 took 0.2732682228088379 seconds\n",
      "number 118 out of 300 took 0.17054510116577148 seconds\n",
      "number 119 out of 300 took 0.28025102615356445 seconds\n",
      "number 120 out of 300 took 0.28024959564208984 seconds\n",
      "number 121 out of 300 took 0.17253947257995605 seconds\n",
      "number 122 out of 300 took 0.2782561779022217 seconds\n",
      "number 123 out of 300 took 0.2782564163208008 seconds\n",
      "number 124 out of 300 took 0.2762601375579834 seconds\n",
      "number 125 out of 300 took 0.2812492847442627 seconds\n",
      "number 126 out of 300 took 0.28523707389831543 seconds\n",
      "number 127 out of 300 took 0.27526378631591797 seconds\n",
      "number 128 out of 300 took 0.2762601375579834 seconds\n",
      "number 129 out of 300 took 0.27725863456726074 seconds\n",
      "number 130 out of 300 took 0.2762606143951416 seconds\n",
      "number 131 out of 300 took 0.27526402473449707 seconds\n",
      "number 132 out of 300 took 0.1685490608215332 seconds\n",
      "number 133 out of 300 took 0.16954612731933594 seconds\n",
      "number 134 out of 300 took 0.2732691764831543 seconds\n",
      "number 135 out of 300 took 0.1655580997467041 seconds\n",
      "number 136 out of 300 took 0.27725887298583984 seconds\n",
      "number 137 out of 300 took 0.2762606143951416 seconds\n",
      "number 138 out of 300 took 0.2792537212371826 seconds\n",
      "number 139 out of 300 took 0.2792544364929199 seconds\n",
      "number 140 out of 300 took 0.27426671981811523 seconds\n",
      "number 141 out of 300 took 0.17054438591003418 seconds\n",
      "number 142 out of 300 took 0.2792515754699707 seconds\n",
      "number 143 out of 300 took 0.2782576084136963 seconds\n",
      "number 144 out of 300 took 0.28324222564697266 seconds\n",
      "number 145 out of 300 took 0.17253804206848145 seconds\n",
      "number 146 out of 300 took 0.2792544364929199 seconds\n",
      "number 147 out of 300 took 0.17054295539855957 seconds\n",
      "number 148 out of 300 took 0.279254674911499 seconds\n",
      "number 149 out of 300 took 0.2822456359863281 seconds\n",
      "number 150 out of 300 took 0.2822458744049072 seconds\n",
      "number 151 out of 300 took 0.16954636573791504 seconds\n",
      "number 152 out of 300 took 0.276261568069458 seconds\n",
      "number 153 out of 300 took 0.1655576229095459 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 154 out of 300 took 0.2792534828186035 seconds\n",
      "number 155 out of 300 took 0.2792530059814453 seconds\n",
      "number 156 out of 300 took 0.2732686996459961 seconds\n",
      "number 157 out of 300 took 0.2792544364929199 seconds\n",
      "number 158 out of 300 took 0.16954612731933594 seconds\n",
      "number 159 out of 300 took 0.27426624298095703 seconds\n",
      "number 160 out of 300 took 0.2762613296508789 seconds\n",
      "number 161 out of 300 took 0.27227187156677246 seconds\n",
      "number 162 out of 300 took 0.2762627601623535 seconds\n",
      "number 163 out of 300 took 0.1685490608215332 seconds\n",
      "number 164 out of 300 took 0.17253804206848145 seconds\n",
      "number 165 out of 300 took 0.2762618064880371 seconds\n",
      "number 166 out of 300 took 0.27426767349243164 seconds\n",
      "number 167 out of 300 took 0.282245397567749 seconds\n",
      "number 168 out of 300 took 0.2792534828186035 seconds\n",
      "number 169 out of 300 took 0.2792518138885498 seconds\n",
      "number 170 out of 300 took 0.29122185707092285 seconds\n",
      "number 171 out of 300 took 0.2812492847442627 seconds\n",
      "number 172 out of 300 took 0.16755127906799316 seconds\n",
      "number 173 out of 300 took 0.2792532444000244 seconds\n",
      "number 174 out of 300 took 0.2782557010650635 seconds\n",
      "number 175 out of 300 took 0.28224658966064453 seconds\n",
      "number 176 out of 300 took 0.27426600456237793 seconds\n",
      "number 177 out of 300 took 0.2762610912322998 seconds\n",
      "number 178 out of 300 took 0.27426719665527344 seconds\n",
      "number 179 out of 300 took 0.2792549133300781 seconds\n",
      "number 180 out of 300 took 0.16755175590515137 seconds\n",
      "number 181 out of 300 took 0.17353558540344238 seconds\n",
      "number 182 out of 300 took 0.2792525291442871 seconds\n",
      "number 183 out of 300 took 0.27726006507873535 seconds\n",
      "number 184 out of 300 took 0.16954731941223145 seconds\n",
      "number 185 out of 300 took 0.17253875732421875 seconds\n",
      "number 186 out of 300 took 0.1685502529144287 seconds\n",
      "number 187 out of 300 took 0.2822439670562744 seconds\n",
      "number 188 out of 300 took 0.2822456359863281 seconds\n",
      "number 189 out of 300 took 0.2782564163208008 seconds\n",
      "number 190 out of 300 took 0.2762625217437744 seconds\n",
      "number 191 out of 300 took 0.2842378616333008 seconds\n",
      "number 192 out of 300 took 0.1655580997467041 seconds\n",
      "number 193 out of 300 took 0.28024983406066895 seconds\n",
      "number 194 out of 300 took 0.2792544364929199 seconds\n",
      "number 195 out of 300 took 0.27227067947387695 seconds\n",
      "number 196 out of 300 took 0.27526426315307617 seconds\n",
      "number 197 out of 300 took 0.27725839614868164 seconds\n",
      "number 198 out of 300 took 0.27227258682250977 seconds\n",
      "number 199 out of 300 took 0.2842388153076172 seconds\n",
      "number 200 out of 300 took 0.27526402473449707 seconds\n",
      "number 201 out of 300 took 0.27426838874816895 seconds\n",
      "number 202 out of 300 took 0.2782557010650635 seconds\n",
      "number 203 out of 300 took 0.27725934982299805 seconds\n",
      "number 204 out of 300 took 0.27526235580444336 seconds\n",
      "number 205 out of 300 took 0.2752652168273926 seconds\n",
      "number 206 out of 300 took 0.16755223274230957 seconds\n",
      "number 207 out of 300 took 0.28324341773986816 seconds\n",
      "number 208 out of 300 took 0.27725791931152344 seconds\n",
      "number 209 out of 300 took 0.27426743507385254 seconds\n",
      "number 210 out of 300 took 0.16755199432373047 seconds\n",
      "number 211 out of 300 took 0.2842402458190918 seconds\n",
      "number 212 out of 300 took 0.2812478542327881 seconds\n",
      "number 213 out of 300 took 0.2762608528137207 seconds\n",
      "number 214 out of 300 took 0.1685497760772705 seconds\n",
      "number 215 out of 300 took 0.2792532444000244 seconds\n",
      "number 216 out of 300 took 0.27725934982299805 seconds\n",
      "number 217 out of 300 took 0.16954684257507324 seconds\n",
      "number 218 out of 300 took 0.2792539596557617 seconds\n",
      "number 219 out of 300 took 0.16954660415649414 seconds\n",
      "number 220 out of 300 took 0.27725911140441895 seconds\n",
      "number 221 out of 300 took 0.2812466621398926 seconds\n",
      "number 222 out of 300 took 0.28025031089782715 seconds\n",
      "number 223 out of 300 took 0.16755294799804688 seconds\n",
      "number 224 out of 300 took 0.2812478542327881 seconds\n",
      "number 225 out of 300 took 0.27725791931152344 seconds\n",
      "number 226 out of 300 took 0.27725911140441895 seconds\n",
      "number 227 out of 300 took 0.17054367065429688 seconds\n",
      "number 228 out of 300 took 0.2762618064880371 seconds\n",
      "number 229 out of 300 took 0.2792541980743408 seconds\n",
      "number 230 out of 300 took 0.27725768089294434 seconds\n",
      "number 231 out of 300 took 0.27725887298583984 seconds\n",
      "number 232 out of 300 took 0.16655468940734863 seconds\n",
      "number 233 out of 300 took 0.17353582382202148 seconds\n",
      "number 234 out of 300 took 0.2792541980743408 seconds\n",
      "number 235 out of 300 took 0.28224635124206543 seconds\n",
      "number 236 out of 300 took 0.28025007247924805 seconds\n",
      "number 237 out of 300 took 0.2782564163208008 seconds\n",
      "number 238 out of 300 took 0.2762613296508789 seconds\n",
      "number 239 out of 300 took 0.28025126457214355 seconds\n",
      "number 240 out of 300 took 0.27725815773010254 seconds\n",
      "number 241 out of 300 took 0.2782559394836426 seconds\n",
      "number 242 out of 300 took 0.17054462432861328 seconds\n",
      "number 243 out of 300 took 0.28025054931640625 seconds\n",
      "number 244 out of 300 took 0.17253899574279785 seconds\n",
      "number 245 out of 300 took 0.1735365390777588 seconds\n",
      "number 246 out of 300 took 0.16954612731933594 seconds\n",
      "number 247 out of 300 took 0.2782552242279053 seconds\n",
      "number 248 out of 300 took 0.2752645015716553 seconds\n",
      "number 249 out of 300 took 0.17154169082641602 seconds\n",
      "number 250 out of 300 took 0.17453265190124512 seconds\n",
      "number 251 out of 300 took 0.2762625217437744 seconds\n",
      "number 252 out of 300 took 0.2742655277252197 seconds\n",
      "number 253 out of 300 took 0.2732698917388916 seconds\n",
      "number 254 out of 300 took 0.16954636573791504 seconds\n",
      "number 255 out of 300 took 0.27725839614868164 seconds\n",
      "number 256 out of 300 took 0.16655492782592773 seconds\n",
      "number 257 out of 300 took 0.2762622833251953 seconds\n",
      "number 258 out of 300 took 0.16755199432373047 seconds\n",
      "number 259 out of 300 took 0.1685481071472168 seconds\n",
      "number 260 out of 300 took 0.279254674911499 seconds\n",
      "number 261 out of 300 took 0.27526283264160156 seconds\n",
      "number 262 out of 300 took 0.2752652168273926 seconds\n",
      "number 263 out of 300 took 0.2782566547393799 seconds\n",
      "number 264 out of 300 took 0.27426624298095703 seconds\n",
      "number 265 out of 300 took 0.27526259422302246 seconds\n",
      "number 266 out of 300 took 0.16954755783081055 seconds\n",
      "number 267 out of 300 took 0.27725791931152344 seconds\n",
      "number 268 out of 300 took 0.27725982666015625 seconds\n",
      "number 269 out of 300 took 0.27426695823669434 seconds\n",
      "number 270 out of 300 took 0.28025007247924805 seconds\n",
      "number 271 out of 300 took 0.2782561779022217 seconds\n",
      "number 272 out of 300 took 0.2752649784088135 seconds\n",
      "number 273 out of 300 took 0.27725958824157715 seconds\n",
      "number 274 out of 300 took 0.2812464237213135 seconds\n",
      "number 275 out of 300 took 0.16655492782592773 seconds\n",
      "number 276 out of 300 took 0.2762620449066162 seconds\n",
      "number 277 out of 300 took 0.2762608528137207 seconds\n",
      "number 278 out of 300 took 0.27725911140441895 seconds\n",
      "number 279 out of 300 took 0.27725958824157715 seconds\n",
      "number 280 out of 300 took 0.27526330947875977 seconds\n",
      "number 281 out of 300 took 0.2792530059814453 seconds\n",
      "number 282 out of 300 took 0.1685497760772705 seconds\n",
      "number 283 out of 300 took 0.2782554626464844 seconds\n",
      "number 284 out of 300 took 0.168548583984375 seconds\n",
      "number 285 out of 300 took 0.17154216766357422 seconds\n",
      "number 286 out of 300 took 0.2842400074005127 seconds\n",
      "number 287 out of 300 took 0.2812478542327881 seconds\n",
      "number 288 out of 300 took 0.27725934982299805 seconds\n",
      "number 289 out of 300 took 0.2822444438934326 seconds\n",
      "number 290 out of 300 took 0.27725982666015625 seconds\n",
      "number 291 out of 300 took 0.27526307106018066 seconds\n",
      "number 292 out of 300 took 0.168548583984375 seconds\n",
      "number 293 out of 300 took 0.2762627601623535 seconds\n",
      "number 294 out of 300 took 0.27725744247436523 seconds\n",
      "number 295 out of 300 took 0.1685504913330078 seconds\n",
      "number 296 out of 300 took 0.2712743282318115 seconds\n",
      "number 297 out of 300 took 0.2752645015716553 seconds\n",
      "number 298 out of 300 took 0.165557861328125 seconds\n",
      "number 299 out of 300 took 0.27825498580932617 seconds\n"
     ]
    }
   ],
   "source": [
    "estimators_repeater(estimators=[RandomForestClassifier(),AdaBoostClassifier(),SVC(),LogisticRegression()],x=x,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "31f3310e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LogisticRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RandomForestClassifier  AdaBoostClassifier    SVC  LogisticRegression\n",
       "count                   300.0               300.0  300.0               300.0\n",
       "mean                      1.0                 1.0    1.0                 1.0\n",
       "std                       0.0                 0.0    0.0                 0.0\n",
       "min                       1.0                 1.0    1.0                 1.0\n",
       "25%                       1.0                 1.0    1.0                 1.0\n",
       "50%                       1.0                 1.0    1.0                 1.0\n",
       "75%                       1.0                 1.0    1.0                 1.0\n",
       "max                       1.0                 1.0    1.0                 1.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_score_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "16b3db99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LogisticRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.966267</td>\n",
       "      <td>0.973867</td>\n",
       "      <td>0.989467</td>\n",
       "      <td>0.995333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.032023</td>\n",
       "      <td>0.029256</td>\n",
       "      <td>0.019381</td>\n",
       "      <td>0.012862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.880000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.840000</td>\n",
       "      <td>0.960000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.960000</td>\n",
       "      <td>0.960000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RandomForestClassifier  AdaBoostClassifier         SVC  \\\n",
       "count              300.000000          300.000000  300.000000   \n",
       "mean                 0.966267            0.973867    0.989467   \n",
       "std                  0.032023            0.029256    0.019381   \n",
       "min                  0.880000            0.840000    0.840000   \n",
       "25%                  0.960000            0.960000    0.960000   \n",
       "50%                  0.960000            0.960000    1.000000   \n",
       "75%                  1.000000            1.000000    1.000000   \n",
       "max                  1.000000            1.000000    1.000000   \n",
       "\n",
       "       LogisticRegression  \n",
       "count          300.000000  \n",
       "mean             0.995333  \n",
       "std              0.012862  \n",
       "min              0.960000  \n",
       "25%              1.000000  \n",
       "50%              1.000000  \n",
       "75%              1.000000  \n",
       "max              1.000000  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_score_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bf0d6a8d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LogisticRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.155531</td>\n",
       "      <td>0.083557</td>\n",
       "      <td>0.002902</td>\n",
       "      <td>0.008344</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.002691</td>\n",
       "      <td>0.046734</td>\n",
       "      <td>0.000402</td>\n",
       "      <td>0.000930</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.150596</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.001993</td>\n",
       "      <td>0.004986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.153590</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.002991</td>\n",
       "      <td>0.007978</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.154587</td>\n",
       "      <td>0.109707</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.007979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.156582</td>\n",
       "      <td>0.111701</td>\n",
       "      <td>0.002992</td>\n",
       "      <td>0.008976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.174534</td>\n",
       "      <td>0.124666</td>\n",
       "      <td>0.003991</td>\n",
       "      <td>0.012965</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RandomForestClassifier  AdaBoostClassifier         SVC  \\\n",
       "count              300.000000          300.000000  300.000000   \n",
       "mean                 0.155531            0.083557    0.002902   \n",
       "std                  0.002691            0.046734    0.000402   \n",
       "min                  0.150596            0.002991    0.001993   \n",
       "25%                  0.153590            0.003991    0.002991   \n",
       "50%                  0.154587            0.109707    0.002992   \n",
       "75%                  0.156582            0.111701    0.002992   \n",
       "max                  0.174534            0.124666    0.003991   \n",
       "\n",
       "       LogisticRegression  \n",
       "count          300.000000  \n",
       "mean             0.008344  \n",
       "std              0.000930  \n",
       "min              0.004986  \n",
       "25%              0.007978  \n",
       "50%              0.007979  \n",
       "75%              0.008976  \n",
       "max              0.012965  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "timing_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "5175a8f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def estimators_repeater2(estimators=[RandomForestClassifier(),AdaBoostClassifier(),SVC()],tr_slicer=(None,None),tst_slicer=(None,None),loops=300,scorer=recall_score,x=x,y=y):\n",
    "    training_score={}\n",
    "    testing_score={}\n",
    "    timing={}\n",
    "    for cl in estimators:\n",
    "        cl_name=cl.__class__.__name__\n",
    "        training_score[cl_name]=[]\n",
    "        testing_score[cl_name]=[]\n",
    "        timing[cl_name]=[]\n",
    "    for i in range(loops):\n",
    "        k1=time()\n",
    "        x_train, x_test, y_train, y_test=train_test_split(x,y,random_state=i)\n",
    "        for cl in estimators:\n",
    "            a=time()\n",
    "            cl_name=cl.__class__.__name__\n",
    "            clean_cl=clone(cl)\n",
    "            clean_cl.fit(x_train[tr_slicer[0]:tr_slicer[1]],y_train[tr_slicer[0]:tr_slicer[1]])\n",
    "            training_score[cl_name].append(scorer(y_train[tr_slicer[0]:tr_slicer[1]],clean_cl.predict(x_train[tr_slicer[0]:tr_slicer[1]])))\n",
    "            testing_score[cl_name].append(scorer(y_test[tst_slicer[0]:tst_slicer[1]],clean_cl.predict(x_test[tst_slicer[0]:tst_slicer[1]])))\n",
    "            b=time()                                \n",
    "            timing[cl_name].append(b-a)\n",
    "        k2=time()\n",
    "        print(f'number {i} out of {loops} took {k2-k1} seconds')\n",
    "    global training_score_df\n",
    "    training_score_df=pd.DataFrame(training_score)\n",
    "    global testing_score_df\n",
    "    testing_score_df=pd.DataFrame(testing_score)\n",
    "    global timing_df\n",
    "    timing_df=pd.DataFrame(timing)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f45fe35b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 0 out of 300 took 0.28623223304748535 seconds\n",
      "number 1 out of 300 took 0.28424072265625 seconds\n",
      "number 2 out of 300 took 0.2822446823120117 seconds\n",
      "number 3 out of 300 took 0.204453706741333 seconds\n",
      "number 4 out of 300 took 0.3031885623931885 seconds\n",
      "number 5 out of 300 took 0.2892270088195801 seconds\n",
      "number 6 out of 300 took 0.29720544815063477 seconds\n",
      "number 7 out of 300 took 0.18650364875793457 seconds\n",
      "number 8 out of 300 took 0.32114076614379883 seconds\n",
      "number 9 out of 300 took 0.29620838165283203 seconds\n",
      "number 10 out of 300 took 0.2932164669036865 seconds\n",
      "number 11 out of 300 took 0.290224552154541 seconds\n",
      "number 12 out of 300 took 0.28822922706604004 seconds\n",
      "number 13 out of 300 took 0.28523731231689453 seconds\n",
      "number 14 out of 300 took 0.2812495231628418 seconds\n",
      "number 15 out of 300 took 0.28523707389831543 seconds\n",
      "number 16 out of 300 took 0.2982039451599121 seconds\n",
      "number 17 out of 300 took 0.3400912284851074 seconds\n",
      "number 18 out of 300 took 0.28922557830810547 seconds\n",
      "number 19 out of 300 took 0.34108805656433105 seconds\n",
      "number 20 out of 300 took 0.31316375732421875 seconds\n",
      "number 21 out of 300 took 0.3151571750640869 seconds\n",
      "number 22 out of 300 took 0.28822946548461914 seconds\n",
      "number 23 out of 300 took 0.2892265319824219 seconds\n",
      "number 24 out of 300 took 0.34108662605285645 seconds\n",
      "number 25 out of 300 took 0.33310985565185547 seconds\n",
      "number 26 out of 300 took 0.29620838165283203 seconds\n",
      "number 27 out of 300 took 0.2822446823120117 seconds\n",
      "number 28 out of 300 took 0.2842411994934082 seconds\n",
      "number 29 out of 300 took 0.3361020088195801 seconds\n",
      "number 30 out of 300 took 0.30219221115112305 seconds\n",
      "number 31 out of 300 took 0.18350839614868164 seconds\n",
      "number 32 out of 300 took 0.18151497840881348 seconds\n",
      "number 33 out of 300 took 0.29122281074523926 seconds\n",
      "number 34 out of 300 took 0.18450593948364258 seconds\n",
      "number 35 out of 300 took 0.2952115535736084 seconds\n",
      "number 36 out of 300 took 0.307178258895874 seconds\n",
      "number 37 out of 300 took 0.3001973628997803 seconds\n",
      "number 38 out of 300 took 0.292219877243042 seconds\n",
      "number 39 out of 300 took 0.18550395965576172 seconds\n",
      "number 40 out of 300 took 0.2154238224029541 seconds\n",
      "number 41 out of 300 took 0.3181490898132324 seconds\n",
      "number 42 out of 300 took 0.18550419807434082 seconds\n",
      "number 43 out of 300 took 0.18450689315795898 seconds\n",
      "number 44 out of 300 took 0.3141608238220215 seconds\n",
      "number 45 out of 300 took 0.30518388748168945 seconds\n",
      "number 46 out of 300 took 0.1874988079071045 seconds\n",
      "number 47 out of 300 took 0.29919958114624023 seconds\n",
      "number 48 out of 300 took 0.3061809539794922 seconds\n",
      "number 49 out of 300 took 0.30019712448120117 seconds\n",
      "number 50 out of 300 took 0.18450593948364258 seconds\n",
      "number 51 out of 300 took 0.3011949062347412 seconds\n",
      "number 52 out of 300 took 0.2922189235687256 seconds\n",
      "number 53 out of 300 took 0.2872328758239746 seconds\n",
      "number 54 out of 300 took 0.3261275291442871 seconds\n",
      "number 55 out of 300 took 0.2872326374053955 seconds\n",
      "number 56 out of 300 took 0.2952101230621338 seconds\n",
      "number 57 out of 300 took 0.3031909465789795 seconds\n",
      "number 58 out of 300 took 0.17752385139465332 seconds\n",
      "number 59 out of 300 took 0.1845076084136963 seconds\n",
      "number 60 out of 300 took 0.29421162605285645 seconds\n",
      "number 61 out of 300 took 0.2952108383178711 seconds\n",
      "number 62 out of 300 took 0.30219268798828125 seconds\n",
      "number 63 out of 300 took 0.3031880855560303 seconds\n",
      "number 64 out of 300 took 0.28823065757751465 seconds\n",
      "number 65 out of 300 took 0.30518412590026855 seconds\n",
      "number 66 out of 300 took 0.18350815773010254 seconds\n",
      "number 67 out of 300 took 0.28623485565185547 seconds\n",
      "number 68 out of 300 took 0.2792544364929199 seconds\n",
      "number 69 out of 300 took 0.28324222564697266 seconds\n",
      "number 70 out of 300 took 0.29122233390808105 seconds\n",
      "number 71 out of 300 took 0.2932147979736328 seconds\n",
      "number 72 out of 300 took 0.2842402458190918 seconds\n",
      "number 73 out of 300 took 0.29920029640197754 seconds\n",
      "number 74 out of 300 took 0.3171525001525879 seconds\n",
      "number 75 out of 300 took 0.2044520378112793 seconds\n",
      "number 76 out of 300 took 0.29720544815063477 seconds\n",
      "number 77 out of 300 took 0.31615376472473145 seconds\n",
      "number 78 out of 300 took 0.18251299858093262 seconds\n",
      "number 79 out of 300 took 0.29720449447631836 seconds\n",
      "number 80 out of 300 took 0.29421353340148926 seconds\n",
      "number 81 out of 300 took 0.30019688606262207 seconds\n",
      "number 82 out of 300 took 0.20644783973693848 seconds\n",
      "number 83 out of 300 took 0.2932162284851074 seconds\n",
      "number 84 out of 300 took 0.28523731231689453 seconds\n",
      "number 85 out of 300 took 0.29122161865234375 seconds\n",
      "number 86 out of 300 took 0.18051648139953613 seconds\n",
      "number 87 out of 300 took 0.2982027530670166 seconds\n",
      "number 88 out of 300 took 0.29720520973205566 seconds\n",
      "number 89 out of 300 took 0.29620862007141113 seconds\n",
      "number 90 out of 300 took 0.19747328758239746 seconds\n",
      "number 91 out of 300 took 0.31116724014282227 seconds\n",
      "number 92 out of 300 took 0.29919934272766113 seconds\n",
      "number 93 out of 300 took 0.28822946548461914 seconds\n",
      "number 94 out of 300 took 0.29620862007141113 seconds\n",
      "number 95 out of 300 took 0.18949294090270996 seconds\n",
      "number 96 out of 300 took 0.2902235984802246 seconds\n",
      "number 97 out of 300 took 0.2952108383178711 seconds\n",
      "number 98 out of 300 took 0.29919958114624023 seconds\n",
      "number 99 out of 300 took 0.18550515174865723 seconds\n",
      "number 100 out of 300 took 0.29620814323425293 seconds\n",
      "number 101 out of 300 took 0.28822827339172363 seconds\n",
      "number 102 out of 300 took 0.17752623558044434 seconds\n",
      "number 103 out of 300 took 0.1795194149017334 seconds\n",
      "number 104 out of 300 took 0.17852306365966797 seconds\n",
      "number 105 out of 300 took 0.2872314453125 seconds\n",
      "number 106 out of 300 took 0.17752623558044434 seconds\n",
      "number 107 out of 300 took 0.2842411994934082 seconds\n",
      "number 108 out of 300 took 0.2822434902191162 seconds\n",
      "number 109 out of 300 took 0.2842411994934082 seconds\n",
      "number 110 out of 300 took 0.2842402458190918 seconds\n",
      "number 111 out of 300 took 0.1765275001525879 seconds\n",
      "number 112 out of 300 took 0.1765289306640625 seconds\n",
      "number 113 out of 300 took 0.3111691474914551 seconds\n",
      "number 114 out of 300 took 0.30318784713745117 seconds\n",
      "number 115 out of 300 took 0.1765289306640625 seconds\n",
      "number 116 out of 300 took 0.19448041915893555 seconds\n",
      "number 117 out of 300 took 0.29421329498291016 seconds\n",
      "number 118 out of 300 took 0.18550395965576172 seconds\n",
      "number 119 out of 300 took 0.3011951446533203 seconds\n",
      "number 120 out of 300 took 0.3091740608215332 seconds\n",
      "number 121 out of 300 took 0.17253780364990234 seconds\n",
      "number 122 out of 300 took 0.290224552154541 seconds\n",
      "number 123 out of 300 took 0.2922194004058838 seconds\n",
      "number 124 out of 300 took 0.2822446823120117 seconds\n",
      "number 125 out of 300 took 0.3041872978210449 seconds\n",
      "number 126 out of 300 took 0.29919934272766113 seconds\n",
      "number 127 out of 300 took 0.3400919437408447 seconds\n",
      "number 128 out of 300 took 0.30019569396972656 seconds\n",
      "number 129 out of 300 took 0.3111684322357178 seconds\n",
      "number 130 out of 300 took 0.2902247905731201 seconds\n",
      "number 131 out of 300 took 0.29122185707092285 seconds\n",
      "number 132 out of 300 took 0.17553091049194336 seconds\n",
      "number 133 out of 300 took 0.18051743507385254 seconds\n",
      "number 134 out of 300 took 0.2892262935638428 seconds\n",
      "number 135 out of 300 took 0.17253875732421875 seconds\n",
      "number 136 out of 300 took 0.2892265319824219 seconds\n",
      "number 137 out of 300 took 0.28822922706604004 seconds\n",
      "number 138 out of 300 took 0.3111701011657715 seconds\n",
      "number 139 out of 300 took 0.3321113586425781 seconds\n",
      "number 140 out of 300 took 0.32213807106018066 seconds\n",
      "number 141 out of 300 took 0.1845076084136963 seconds\n",
      "number 142 out of 300 took 0.29720449447631836 seconds\n",
      "number 143 out of 300 took 0.31316399574279785 seconds\n",
      "number 144 out of 300 took 0.30817604064941406 seconds\n",
      "number 145 out of 300 took 0.19148731231689453 seconds\n",
      "number 146 out of 300 took 0.2922213077545166 seconds\n",
      "number 147 out of 300 took 0.18051576614379883 seconds\n",
      "number 148 out of 300 took 0.3061814308166504 seconds\n",
      "number 149 out of 300 took 0.29920053482055664 seconds\n",
      "number 150 out of 300 took 0.3261277675628662 seconds\n",
      "number 151 out of 300 took 0.19049072265625 seconds\n",
      "number 152 out of 300 took 0.2932157516479492 seconds\n",
      "number 153 out of 300 took 0.17752599716186523 seconds\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number 154 out of 300 took 0.3001973628997803 seconds\n",
      "number 155 out of 300 took 0.32213878631591797 seconds\n",
      "number 156 out of 300 took 0.3121659755706787 seconds\n",
      "number 157 out of 300 took 0.2952108383178711 seconds\n",
      "number 158 out of 300 took 0.18051695823669434 seconds\n",
      "number 159 out of 300 took 0.34108877182006836 seconds\n",
      "number 160 out of 300 took 0.354053258895874 seconds\n",
      "number 161 out of 300 took 0.3091731071472168 seconds\n",
      "number 162 out of 300 took 0.3061816692352295 seconds\n",
      "number 163 out of 300 took 0.18450665473937988 seconds\n",
      "number 164 out of 300 took 0.18151569366455078 seconds\n",
      "number 165 out of 300 took 0.325131893157959 seconds\n",
      "number 166 out of 300 took 0.3061819076538086 seconds\n",
      "number 167 out of 300 took 0.3201427459716797 seconds\n",
      "number 168 out of 300 took 0.31017065048217773 seconds\n",
      "number 169 out of 300 took 0.3001973628997803 seconds\n",
      "number 170 out of 300 took 0.2872323989868164 seconds\n",
      "number 171 out of 300 took 0.29321718215942383 seconds\n",
      "number 172 out of 300 took 0.1855020523071289 seconds\n",
      "number 173 out of 300 took 0.2972071170806885 seconds\n",
      "number 174 out of 300 took 0.2982017993927002 seconds\n",
      "number 175 out of 300 took 0.28324174880981445 seconds\n",
      "number 176 out of 300 took 0.29421305656433105 seconds\n",
      "number 177 out of 300 took 0.31914758682250977 seconds\n",
      "number 178 out of 300 took 0.3341071605682373 seconds\n",
      "number 179 out of 300 took 0.3011934757232666 seconds\n",
      "number 180 out of 300 took 0.17553138732910156 seconds\n",
      "number 181 out of 300 took 0.18949341773986816 seconds\n",
      "number 182 out of 300 took 0.29720568656921387 seconds\n",
      "number 183 out of 300 took 0.3011953830718994 seconds\n",
      "number 184 out of 300 took 0.2014603614807129 seconds\n",
      "number 185 out of 300 took 0.19148802757263184 seconds\n",
      "number 186 out of 300 took 0.1874980926513672 seconds\n",
      "number 187 out of 300 took 0.29720640182495117 seconds\n",
      "number 188 out of 300 took 0.29421353340148926 seconds\n",
      "number 189 out of 300 took 0.28623485565185547 seconds\n",
      "number 190 out of 300 took 0.2902247905731201 seconds\n",
      "number 191 out of 300 took 0.2822446823120117 seconds\n",
      "number 192 out of 300 took 0.17453455924987793 seconds\n",
      "number 193 out of 300 took 0.3041863441467285 seconds\n",
      "number 194 out of 300 took 0.3071784973144531 seconds\n",
      "number 195 out of 300 took 0.28822970390319824 seconds\n",
      "number 196 out of 300 took 0.2902235984802246 seconds\n",
      "number 197 out of 300 took 0.3420853614807129 seconds\n",
      "number 198 out of 300 took 0.2902233600616455 seconds\n",
      "number 199 out of 300 took 0.28324365615844727 seconds\n",
      "number 200 out of 300 took 0.298201322555542 seconds\n",
      "number 201 out of 300 took 0.29122066497802734 seconds\n",
      "number 202 out of 300 took 0.290224552154541 seconds\n",
      "number 203 out of 300 took 0.28623437881469727 seconds\n",
      "number 204 out of 300 took 0.2872333526611328 seconds\n",
      "number 205 out of 300 took 0.293215274810791 seconds\n",
      "number 206 out of 300 took 0.1795210838317871 seconds\n",
      "number 207 out of 300 took 0.29121971130371094 seconds\n",
      "number 208 out of 300 took 0.30219316482543945 seconds\n",
      "number 209 out of 300 took 0.3121654987335205 seconds\n",
      "number 210 out of 300 took 0.18550467491149902 seconds\n",
      "number 211 out of 300 took 0.2962071895599365 seconds\n",
      "number 212 out of 300 took 0.28324413299560547 seconds\n",
      "number 213 out of 300 took 0.2932159900665283 seconds\n",
      "number 214 out of 300 took 0.20046353340148926 seconds\n",
      "number 215 out of 300 took 0.3091733455657959 seconds\n",
      "number 216 out of 300 took 0.2982032299041748 seconds\n",
      "number 217 out of 300 took 0.1825108528137207 seconds\n",
      "number 218 out of 300 took 0.31316328048706055 seconds\n",
      "number 219 out of 300 took 0.19647526741027832 seconds\n",
      "number 220 out of 300 took 0.3041865825653076 seconds\n",
      "number 221 out of 300 took 0.2932157516479492 seconds\n",
      "number 222 out of 300 took 0.31316208839416504 seconds\n",
      "number 223 out of 300 took 0.17752599716186523 seconds\n",
      "number 224 out of 300 took 0.3181495666503906 seconds\n",
      "number 225 out of 300 took 0.2922186851501465 seconds\n",
      "number 226 out of 300 took 0.28623533248901367 seconds\n",
      "number 227 out of 300 took 0.17553114891052246 seconds\n",
      "number 228 out of 300 took 0.2892262935638428 seconds\n",
      "number 229 out of 300 took 0.2892262935638428 seconds\n",
      "number 230 out of 300 took 0.2872314453125 seconds\n",
      "number 231 out of 300 took 0.28025197982788086 seconds\n",
      "number 232 out of 300 took 0.17553019523620605 seconds\n",
      "number 233 out of 300 took 0.1795201301574707 seconds\n",
      "number 234 out of 300 took 0.29421424865722656 seconds\n",
      "number 235 out of 300 took 0.30817508697509766 seconds\n",
      "number 236 out of 300 took 0.3291199207305908 seconds\n",
      "number 237 out of 300 took 0.30219244956970215 seconds\n",
      "number 238 out of 300 took 0.30019664764404297 seconds\n",
      "number 239 out of 300 took 0.289226770401001 seconds\n",
      "number 240 out of 300 took 0.31316256523132324 seconds\n",
      "number 241 out of 300 took 0.2902231216430664 seconds\n",
      "number 242 out of 300 took 0.17552995681762695 seconds\n",
      "number 243 out of 300 took 0.2862355709075928 seconds\n",
      "number 244 out of 300 took 0.17852163314819336 seconds\n",
      "number 245 out of 300 took 0.19747257232666016 seconds\n",
      "number 246 out of 300 took 0.182511568069458 seconds\n",
      "number 247 out of 300 took 0.29421448707580566 seconds\n",
      "number 248 out of 300 took 0.30019688606262207 seconds\n",
      "number 249 out of 300 took 0.18350958824157715 seconds\n",
      "number 250 out of 300 took 0.1765289306640625 seconds\n",
      "number 251 out of 300 took 0.3121652603149414 seconds\n",
      "number 252 out of 300 took 0.3011941909790039 seconds\n",
      "number 253 out of 300 took 0.2932159900665283 seconds\n",
      "number 254 out of 300 took 0.18051719665527344 seconds\n",
      "number 255 out of 300 took 0.32712721824645996 seconds\n",
      "number 256 out of 300 took 0.18949103355407715 seconds\n",
      "number 257 out of 300 took 0.3001987934112549 seconds\n",
      "number 258 out of 300 took 0.18151330947875977 seconds\n",
      "number 259 out of 300 took 0.17852354049682617 seconds\n",
      "number 260 out of 300 took 0.30518436431884766 seconds\n",
      "number 261 out of 300 took 0.29720568656921387 seconds\n",
      "number 262 out of 300 took 0.29720449447631836 seconds\n",
      "number 263 out of 300 took 0.300199031829834 seconds\n",
      "number 264 out of 300 took 0.31316232681274414 seconds\n",
      "number 265 out of 300 took 0.3001973628997803 seconds\n",
      "number 266 out of 300 took 0.18450522422790527 seconds\n",
      "number 267 out of 300 took 0.30219292640686035 seconds\n",
      "number 268 out of 300 took 0.28822970390319824 seconds\n",
      "number 269 out of 300 took 0.311168909072876 seconds\n",
      "number 270 out of 300 took 0.31017017364501953 seconds\n",
      "number 271 out of 300 took 0.30219078063964844 seconds\n",
      "number 272 out of 300 took 0.30817580223083496 seconds\n",
      "number 273 out of 300 took 0.2922189235687256 seconds\n",
      "number 274 out of 300 took 0.2922184467315674 seconds\n",
      "number 275 out of 300 took 0.18351101875305176 seconds\n",
      "number 276 out of 300 took 0.2982017993927002 seconds\n",
      "number 277 out of 300 took 0.2892270088195801 seconds\n",
      "number 278 out of 300 took 0.29620862007141113 seconds\n",
      "number 279 out of 300 took 0.2982027530670166 seconds\n",
      "number 280 out of 300 took 0.30518388748168945 seconds\n",
      "number 281 out of 300 took 0.28623509407043457 seconds\n",
      "number 282 out of 300 took 0.176527738571167 seconds\n",
      "number 283 out of 300 took 0.2892270088195801 seconds\n",
      "number 284 out of 300 took 0.19148659706115723 seconds\n",
      "number 285 out of 300 took 0.1825122833251953 seconds\n",
      "number 286 out of 300 took 0.290224552154541 seconds\n",
      "number 287 out of 300 took 0.28822898864746094 seconds\n",
      "number 288 out of 300 took 0.28823065757751465 seconds\n",
      "number 289 out of 300 took 0.29122066497802734 seconds\n",
      "number 290 out of 300 took 0.3011949062347412 seconds\n",
      "number 291 out of 300 took 0.28324174880981445 seconds\n",
      "number 292 out of 300 took 0.17553091049194336 seconds\n",
      "number 293 out of 300 took 0.28823041915893555 seconds\n",
      "number 294 out of 300 took 0.29421281814575195 seconds\n",
      "number 295 out of 300 took 0.1795198917388916 seconds\n",
      "number 296 out of 300 took 0.2922182083129883 seconds\n",
      "number 297 out of 300 took 0.2902240753173828 seconds\n",
      "number 298 out of 300 took 0.18051695823669434 seconds\n",
      "number 299 out of 300 took 0.2902252674102783 seconds\n"
     ]
    }
   ],
   "source": [
    "estimators_repeater2(estimators=[RandomForestClassifier(),AdaBoostClassifier(),SVC(),LogisticRegression()],x=x,y=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "7d258930",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>SVC</th>\n",
       "      <th>LogisticRegression</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.000000</td>\n",
       "      <td>300.0</td>\n",
       "      <td>300.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.963810</td>\n",
       "      <td>0.971070</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.045642</td>\n",
       "      <td>0.047851</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.818182</td>\n",
       "      <td>0.733333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.928571</td>\n",
       "      <td>0.933333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       RandomForestClassifier  AdaBoostClassifier    SVC  LogisticRegression\n",
       "count              300.000000          300.000000  300.0               300.0\n",
       "mean                 0.963810            0.971070    1.0                 1.0\n",
       "std                  0.045642            0.047851    0.0                 0.0\n",
       "min                  0.818182            0.733333    1.0                 1.0\n",
       "25%                  0.928571            0.933333    1.0                 1.0\n",
       "50%                  1.000000            1.000000    1.0                 1.0\n",
       "75%                  1.000000            1.000000    1.0                 1.0\n",
       "max                  1.000000            1.000000    1.0                 1.0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "testing_score_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27427ca0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf23fb03",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3739c52d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f2a4fa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "9f417c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pca1</th>\n",
       "      <th>pca2</th>\n",
       "      <th>pca3</th>\n",
       "      <th>pca4</th>\n",
       "      <th>pca5</th>\n",
       "      <th>pca6</th>\n",
       "      <th>pca7</th>\n",
       "      <th>pca8</th>\n",
       "      <th>pca9</th>\n",
       "      <th>pca10</th>\n",
       "      <th>...</th>\n",
       "      <th>pca581</th>\n",
       "      <th>pca582</th>\n",
       "      <th>pca583</th>\n",
       "      <th>pca584</th>\n",
       "      <th>pca585</th>\n",
       "      <th>pca586</th>\n",
       "      <th>pca587</th>\n",
       "      <th>pca588</th>\n",
       "      <th>pca589</th>\n",
       "      <th>pca590</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-33.804476</td>\n",
       "      <td>-2.787982</td>\n",
       "      <td>-5.770776</td>\n",
       "      <td>-30.958220</td>\n",
       "      <td>5.887185</td>\n",
       "      <td>13.407046</td>\n",
       "      <td>2.691613</td>\n",
       "      <td>-14.574579</td>\n",
       "      <td>-9.552975</td>\n",
       "      <td>35.365711</td>\n",
       "      <td>...</td>\n",
       "      <td>0.196188</td>\n",
       "      <td>0.154316</td>\n",
       "      <td>0.327665</td>\n",
       "      <td>0.057420</td>\n",
       "      <td>0.454254</td>\n",
       "      <td>0.043743</td>\n",
       "      <td>-0.494110</td>\n",
       "      <td>0.163552</td>\n",
       "      <td>0.313049</td>\n",
       "      <td>2.829963e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>12.129357</td>\n",
       "      <td>-20.493103</td>\n",
       "      <td>13.751279</td>\n",
       "      <td>-29.977843</td>\n",
       "      <td>-8.738578</td>\n",
       "      <td>-3.651478</td>\n",
       "      <td>-16.750653</td>\n",
       "      <td>18.264358</td>\n",
       "      <td>0.222539</td>\n",
       "      <td>-23.017786</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.231051</td>\n",
       "      <td>0.436648</td>\n",
       "      <td>0.278043</td>\n",
       "      <td>0.841787</td>\n",
       "      <td>0.056323</td>\n",
       "      <td>0.110008</td>\n",
       "      <td>0.127392</td>\n",
       "      <td>0.172217</td>\n",
       "      <td>-0.086814</td>\n",
       "      <td>2.829963e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-4.647118</td>\n",
       "      <td>-27.232655</td>\n",
       "      <td>-10.584373</td>\n",
       "      <td>-4.731128</td>\n",
       "      <td>-26.303871</td>\n",
       "      <td>-22.174773</td>\n",
       "      <td>5.284348</td>\n",
       "      <td>1.192801</td>\n",
       "      <td>23.295138</td>\n",
       "      <td>2.967032</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.016966</td>\n",
       "      <td>0.286153</td>\n",
       "      <td>0.738451</td>\n",
       "      <td>-0.027324</td>\n",
       "      <td>0.026627</td>\n",
       "      <td>-0.631649</td>\n",
       "      <td>0.330128</td>\n",
       "      <td>-0.128202</td>\n",
       "      <td>0.091551</td>\n",
       "      <td>2.829963e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-7.638704</td>\n",
       "      <td>-57.561760</td>\n",
       "      <td>7.498658</td>\n",
       "      <td>5.308718</td>\n",
       "      <td>0.283737</td>\n",
       "      <td>-2.635175</td>\n",
       "      <td>-8.665971</td>\n",
       "      <td>1.103797</td>\n",
       "      <td>-17.317805</td>\n",
       "      <td>-5.960301</td>\n",
       "      <td>...</td>\n",
       "      <td>0.261537</td>\n",
       "      <td>-0.382600</td>\n",
       "      <td>0.365680</td>\n",
       "      <td>0.041219</td>\n",
       "      <td>0.090431</td>\n",
       "      <td>-0.025359</td>\n",
       "      <td>0.661129</td>\n",
       "      <td>0.442092</td>\n",
       "      <td>-0.349987</td>\n",
       "      <td>2.829963e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-31.522639</td>\n",
       "      <td>76.837420</td>\n",
       "      <td>-26.187440</td>\n",
       "      <td>-6.820377</td>\n",
       "      <td>12.824112</td>\n",
       "      <td>-1.214566</td>\n",
       "      <td>11.631132</td>\n",
       "      <td>-9.568467</td>\n",
       "      <td>-10.434659</td>\n",
       "      <td>-4.633602</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.150812</td>\n",
       "      <td>0.078911</td>\n",
       "      <td>0.046604</td>\n",
       "      <td>-0.195311</td>\n",
       "      <td>0.079283</td>\n",
       "      <td>-0.053218</td>\n",
       "      <td>0.263967</td>\n",
       "      <td>0.386297</td>\n",
       "      <td>-0.499102</td>\n",
       "      <td>2.829963e-15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 590 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        pca1       pca2       pca3       pca4       pca5       pca6  \\\n",
       "0 -33.804476  -2.787982  -5.770776 -30.958220   5.887185  13.407046   \n",
       "1  12.129357 -20.493103  13.751279 -29.977843  -8.738578  -3.651478   \n",
       "2  -4.647118 -27.232655 -10.584373  -4.731128 -26.303871 -22.174773   \n",
       "3  -7.638704 -57.561760   7.498658   5.308718   0.283737  -2.635175   \n",
       "4 -31.522639  76.837420 -26.187440  -6.820377  12.824112  -1.214566   \n",
       "\n",
       "        pca7       pca8       pca9      pca10  ...    pca581    pca582  \\\n",
       "0   2.691613 -14.574579  -9.552975  35.365711  ...  0.196188  0.154316   \n",
       "1 -16.750653  18.264358   0.222539 -23.017786  ... -1.231051  0.436648   \n",
       "2   5.284348   1.192801  23.295138   2.967032  ... -0.016966  0.286153   \n",
       "3  -8.665971   1.103797 -17.317805  -5.960301  ...  0.261537 -0.382600   \n",
       "4  11.631132  -9.568467 -10.434659  -4.633602  ... -0.150812  0.078911   \n",
       "\n",
       "     pca583    pca584    pca585    pca586    pca587    pca588    pca589  \\\n",
       "0  0.327665  0.057420  0.454254  0.043743 -0.494110  0.163552  0.313049   \n",
       "1  0.278043  0.841787  0.056323  0.110008  0.127392  0.172217 -0.086814   \n",
       "2  0.738451 -0.027324  0.026627 -0.631649  0.330128 -0.128202  0.091551   \n",
       "3  0.365680  0.041219  0.090431 -0.025359  0.661129  0.442092 -0.349987   \n",
       "4  0.046604 -0.195311  0.079283 -0.053218  0.263967  0.386297 -0.499102   \n",
       "\n",
       "         pca590  \n",
       "0  2.829963e-15  \n",
       "1  2.829963e-15  \n",
       "2  2.829963e-15  \n",
       "3  2.829963e-15  \n",
       "4  2.829963e-15  \n",
       "\n",
       "[5 rows x 590 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=590)\n",
    "pca_array = pca.fit_transform(df2)\n",
    "pca_df = pd.DataFrame(pca_array, index=df2.index,\n",
    "                      columns=[f\"pca{num+1}\" for num in range(590)])\n",
    "pca_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a063f3ab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>설명가능한 분산 비율(고윳값)</th>\n",
       "      <th>기여율</th>\n",
       "      <th>누적기여율</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>pca1</th>\n",
       "      <td>1.553460e+03</td>\n",
       "      <td>8.705178e-02</td>\n",
       "      <td>0.087052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca2</th>\n",
       "      <td>1.347472e+03</td>\n",
       "      <td>7.550873e-02</td>\n",
       "      <td>0.162561</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca3</th>\n",
       "      <td>7.642334e+02</td>\n",
       "      <td>4.282560e-02</td>\n",
       "      <td>0.205386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca4</th>\n",
       "      <td>6.858864e+02</td>\n",
       "      <td>3.843524e-02</td>\n",
       "      <td>0.243821</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca5</th>\n",
       "      <td>4.964501e+02</td>\n",
       "      <td>2.781974e-02</td>\n",
       "      <td>0.271641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca586</th>\n",
       "      <td>2.475582e+00</td>\n",
       "      <td>1.387250e-04</td>\n",
       "      <td>0.999615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca587</th>\n",
       "      <td>2.370171e+00</td>\n",
       "      <td>1.328181e-04</td>\n",
       "      <td>0.999748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca588</th>\n",
       "      <td>2.318629e+00</td>\n",
       "      <td>1.299298e-04</td>\n",
       "      <td>0.999878</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca589</th>\n",
       "      <td>2.185088e+00</td>\n",
       "      <td>1.224465e-04</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pca590</th>\n",
       "      <td>8.022288e-30</td>\n",
       "      <td>4.495476e-34</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>590 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        설명가능한 분산 비율(고윳값)           기여율     누적기여율\n",
       "pca1        1.553460e+03  8.705178e-02  0.087052\n",
       "pca2        1.347472e+03  7.550873e-02  0.162561\n",
       "pca3        7.642334e+02  4.282560e-02  0.205386\n",
       "pca4        6.858864e+02  3.843524e-02  0.243821\n",
       "pca5        4.964501e+02  2.781974e-02  0.271641\n",
       "...                  ...           ...       ...\n",
       "pca586      2.475582e+00  1.387250e-04  0.999615\n",
       "pca587      2.370171e+00  1.328181e-04  0.999748\n",
       "pca588      2.318629e+00  1.299298e-04  0.999878\n",
       "pca589      2.185088e+00  1.224465e-04  1.000000\n",
       "pca590      8.022288e-30  4.495476e-34  1.000000\n",
       "\n",
       "[590 rows x 3 columns]"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result = pd.DataFrame({'설명가능한 분산 비율(고윳값)':pca.explained_variance_,\n",
    "             '기여율':pca.explained_variance_ratio_},\n",
    "            index=np.array([f\"pca{num+1}\" for num in range(590)]))\n",
    "result['누적기여율'] = result['기여율'].cumsum()\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f042c9bb",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_33268/3952059770.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# 784개의 픽셀(특성)을 가지고 있는 데이터 셋\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[0mmnist\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_openml\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'mnist_784'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mversion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mas_frame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtarget\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0muint8\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[0mextra_args\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mall_args\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mextra_args\u001b[0m \u001b[1;33m<=\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m             \u001b[1;31m# extra_args > 0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_openml.py\u001b[0m in \u001b[0;36mfetch_openml\u001b[1;34m(name, version, data_id, data_home, target_column, cache, return_X_y, as_frame)\u001b[0m\n\u001b[0;32m    913\u001b[0m     \u001b[1;31m# obtain the data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m     \u001b[0murl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_DATA_FILE\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_description\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'file_id'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 915\u001b[1;33m     bunch = _download_data_to_bunch(url, return_sparse, data_home,\n\u001b[0m\u001b[0;32m    916\u001b[0m                                     \u001b[0mas_frame\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mbool\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mas_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    917\u001b[0m                                     \u001b[0mfeatures_list\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfeatures_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_openml.py\u001b[0m in \u001b[0;36m_download_data_to_bunch\u001b[1;34m(url, sparse, data_home, as_frame, features_list, data_columns, target_columns, shape, md5_checksum)\u001b[0m\n\u001b[0;32m    631\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mframe\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnominal_attributes\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    632\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 633\u001b[1;33m     out = _retry_with_clean_cache(url, data_home)(\n\u001b[0m\u001b[0;32m    634\u001b[0m         \u001b[0m_load_arff_response\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_home\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    635\u001b[0m                              \u001b[0mreturn_type\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_type\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_openml.py\u001b[0m in \u001b[0;36mwrapper\u001b[1;34m(*args, **kw)\u001b[0m\n\u001b[0;32m     59\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     60\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mHTTPError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m                 \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_openml.py\u001b[0m in \u001b[0;36m_load_arff_response\u001b[1;34m(url, data_home, return_type, encode_nominal, parse_arff, md5_checksum)\u001b[0m\n\u001b[0;32m    498\u001b[0m ) -> Tuple:\n\u001b[0;32m    499\u001b[0m     \u001b[1;34m\"\"\"Load arff data with url and parses arff response with parse_arff\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 500\u001b[1;33m     \u001b[0mresponse\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_open_openml_url\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0murl\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata_home\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    501\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    502\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mclosing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\datasets\\_openml.py\u001b[0m in \u001b[0;36m_open_openml_url\u001b[1;34m(openml_path, data_home)\u001b[0m\n\u001b[0;32m    119\u001b[0m                     \u001b[0mopener\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgzip\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mGzipFile\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    120\u001b[0m                 \u001b[1;32mwith\u001b[0m \u001b[0mopener\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'wb'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 121\u001b[1;33m                     \u001b[0mshutil\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopyfileobj\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfsrc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    122\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    123\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexists\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlocal_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\shutil.py\u001b[0m in \u001b[0;36mcopyfileobj\u001b[1;34m(fsrc, fdst, length)\u001b[0m\n\u001b[0;32m    203\u001b[0m     \u001b[0mfdst_write\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfdst\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    204\u001b[0m     \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 205\u001b[1;33m         \u001b[0mbuf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfsrc_read\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlength\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    206\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mbuf\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m             \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, amt)\u001b[0m\n\u001b[0;32m    460\u001b[0m             \u001b[1;31m# Amount is given, implement using readinto\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    461\u001b[0m             \u001b[0mb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbytearray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mamt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 462\u001b[1;33m             \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    463\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mmemoryview\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtobytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    464\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    494\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    495\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mchunked\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 496\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_readinto_chunked\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    497\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    498\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlength\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_readinto_chunked\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    599\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    600\u001b[0m                 \u001b[0mtemp_mvb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmvb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mchunk_left\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 601\u001b[1;33m                 \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_safe_readinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_mvb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    602\u001b[0m                 \u001b[0mmvb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmvb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    603\u001b[0m                 \u001b[0mtotal_bytes\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\http\\client.py\u001b[0m in \u001b[0;36m_safe_readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    639\u001b[0m                 \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtemp_mvb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    640\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 641\u001b[1;33m                 \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mreadinto\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    642\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    643\u001b[0m                 \u001b[1;32mraise\u001b[0m \u001b[0mIncompleteRead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbytes\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmvb\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mtotal_bytes\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\socket.py\u001b[0m in \u001b[0;36mreadinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m    702\u001b[0m         \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    703\u001b[0m             \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 704\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sock\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    705\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    706\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_timeout_occurred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mrecv_into\u001b[1;34m(self, buffer, nbytes, flags)\u001b[0m\n\u001b[0;32m   1239\u001b[0m                   \u001b[1;34m\"non-zero flags not allowed in calls to recv_into() on %s\"\u001b[0m \u001b[1;33m%\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1240\u001b[0m                   self.__class__)\n\u001b[1;32m-> 1241\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1242\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1243\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrecv_into\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbuffer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnbytes\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mflags\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\ssl.py\u001b[0m in \u001b[0;36mread\u001b[1;34m(self, len, buffer)\u001b[0m\n\u001b[0;32m   1097\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1098\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mbuffer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1099\u001b[1;33m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbuffer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1100\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1101\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_sslobj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# MNIST 데이터 사용하기\n",
    "from sklearn.datasets import fetch_openml\n",
    "\n",
    "# 784개의 픽셀(특성)을 가지고 있는 데이터 셋\n",
    "mnist = fetch_openml('mnist_784', version=1, as_frame=False)\n",
    "mnist.target = mnist.target.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "104ee590",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = mnist[\"data\"]\n",
    "y = mnist[\"target\"]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14cd10eb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
